{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 수치미분 함수\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "        \n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        \n",
    "        self.name = gate_name\n",
    "        \n",
    "        # 입력 데이터, 정답 데이터 초기화\n",
    "        self.__xdata = xdata.reshape(4,2)  # 4개의 입력데이터 x1, x2 에 대하여 batch 처리 행렬\n",
    "        self.__tdata = tdata.reshape(4,1)  # 4개의 입력데이터 x1, x2 에 대한 각각의 계산 값 행렬\n",
    "        \n",
    "        # 2층 hidden layer unit : 6개 가정,  가중치 W2, 바이어스 b2 초기화\n",
    "        self.__W2 = np.random.rand(2,9)  # weight, 2 X 6 matrix\n",
    "        self.__b2 = np.random.rand(9)\n",
    "        \n",
    "        # 3층 output layer unit : 1 개 , 가중치 W3, 바이어스 b3 초기화\n",
    "        self.__W3 = np.random.rand(9,1)\n",
    "        self.__b3 = np.random.rand(1)\n",
    "                        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.__learning_rate = 1e-2\n",
    "    \n",
    "        print(self.name + \" object is created\")\n",
    "            \n",
    "    def feed_forward(self):        # feed forward 를 통하여 손실함수(cross-entropy) 값 계산\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z2 = np.dot(self.__xdata, self.__W2) + self.__b2  # 은닉층의 선형회귀 값\n",
    "        a2 = sigmoid(z2)                                  # 은닉층의 출력\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3            # 출력층의 선형회귀 값\n",
    "        y = a3 = sigmoid(z3)                              # 출력층의 출력\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.__tdata*np.log(y + delta) + (1-self.__tdata)*np.log((1 - y)+delta ) )    \n",
    "    \n",
    "    def loss_val(self):          # 외부 출력을 위한 손실함수(cross-entropy) 값 계산 \n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z2 = np.dot(self.__xdata, self.__W2) + self.__b2  # 은닉층의 선형회귀 값\n",
    "        a2 = sigmoid(z2)                                  # 은닉층의 출력\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3            # 출력층의 선형회귀 값\n",
    "        y = a3 = sigmoid(z3)                              # 출력층의 출력\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.__tdata*np.log(y + delta) + (1-self.__tdata)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    \n",
    "    # 수치미분을 이용하여 손실함수가 최소가 될때 까지 학습하는 함수\n",
    "    def train(self):\n",
    "        \n",
    "        f = lambda x : self.feed_forward()\n",
    "        \n",
    "        print(\"Initial loss value = \", self.loss_val())\n",
    "        \n",
    "        for step in  range(10001):\n",
    "            \n",
    "            self.__W2 -= self.__learning_rate * numerical_derivative(f, self.__W2)\n",
    "    \n",
    "            self.__b2 -= self.__learning_rate * numerical_derivative(f, self.__b2)\n",
    "        \n",
    "            self.__W3 -= self.__learning_rate * numerical_derivative(f, self.__W3)\n",
    "    \n",
    "            self.__b3 -= self.__learning_rate * numerical_derivative(f, self.__b3)\n",
    "    \n",
    "            if (step % 400 == 0):\n",
    "                print(\"\\n*****************************************************************************\")\n",
    "                print(\"step = \", step, \"  , loss value = \", self.loss_val())\n",
    "                print(\"\\nW2 = \" , self.__W2, \"\\n\")\n",
    "                print(\"b2 = \" , self.__b2, \"\\n\")\n",
    "                \n",
    "    \n",
    "    # query, 즉 미래 값 예측 함수\n",
    "    def predict(self, xdata):\n",
    "        \n",
    "        z2 = np.dot(xdata, self.__W2) + self.__b2         # 은닉층의 선형회귀 값\n",
    "        a2 = sigmoid(z2)                                  # 은닉층의 출력\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3            # 출력층의 선형회귀 값\n",
    "        y = a3 = sigmoid(z3)                              # 출력층의 출력\n",
    "    \n",
    "        if y > 0.5:\n",
    "            result = 1  # True\n",
    "        else:\n",
    "            result = 0  # False\n",
    "    \n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND object is created\n",
      "Initial loss value =  12.923866368400887\n",
      "\n",
      "*****************************************************************************\n",
      "step =  0   , loss value =  12.403709816362635\n",
      "\n",
      "W2 =  [[0.62139613 0.25276129 0.37701564 0.78233114 0.67740294 0.40889123\n",
      "  0.96780086 0.81354786 0.18239215]\n",
      " [0.81121706 0.90484247 0.89146185 0.1511099  0.94128184 0.83555085\n",
      "  0.3725448  0.26873639 0.43105563]] \n",
      "\n",
      "b2 =  [0.89949767 0.83876021 0.50987437 0.90626097 0.53263992 0.57009842\n",
      " 0.23364936 0.53575235 0.71018036] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  400   , loss value =  2.178360340432476\n",
      "\n",
      "W2 =  [[0.60162287 0.24047871 0.39325992 0.72314257 0.67450993 0.4098\n",
      "  0.95592984 0.76133998 0.1467767 ]\n",
      " [0.79160402 0.90599049 0.9260757  0.11369156 0.94428426 0.84618772\n",
      "  0.35879184 0.23235382 0.39677052]] \n",
      "\n",
      "b2 =  [0.91572308 0.74047481 0.30455416 0.9620139  0.36227614 0.43495781\n",
      " 0.20317446 0.58729619 0.673433  ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  800   , loss value =  2.065955468450112\n",
      "\n",
      "W2 =  [[0.58870246 0.25439457 0.46785441 0.64487438 0.71644983 0.45337367\n",
      "  0.99649171 0.71474156 0.09863454]\n",
      " [0.77795264 0.92649897 1.01582858 0.06583879 0.98957006 0.89687382\n",
      "  0.38465032 0.20100148 0.34830504]] \n",
      "\n",
      "b2 =  [0.96362478 0.70662233 0.14893036 1.03947077 0.2105944  0.34524382\n",
      " 0.14808142 0.63727594 0.70195853] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1200   , loss value =  1.9075321932751996\n",
      "\n",
      "W2 =  [[0.57534386 0.26940444 0.56152769 0.54367435 0.77806169 0.51025913\n",
      "  1.07838565 0.67222478 0.01504703]\n",
      " [0.76437107 0.94896495 1.12577356 0.00361074 1.05148763 0.96180405\n",
      "  0.43159701 0.17339739 0.26582243]] \n",
      "\n",
      "b2 =  [ 1.01407858  0.66713544 -0.0760492   1.12186953 -0.01589022  0.21390156\n",
      "  0.02804441  0.67951664  0.74189235] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1600   , loss value =  1.683161823187105\n",
      "\n",
      "W2 =  [[ 0.56139296  0.28429435  0.67473143  0.41137705  0.86325665  0.5773012\n",
      "   1.19413953  0.62934897 -0.11900217]\n",
      " [ 0.75114011  0.97163866  1.24710957 -0.07836515  1.1252304   1.03433851\n",
      "   0.48638367  0.147349    0.13728772]] \n",
      "\n",
      "b2 =  [ 1.0686495   0.62392902 -0.37361995  1.20223444 -0.31726501  0.03981769\n",
      " -0.15728776  0.71902616  0.78533693] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2000   , loss value =  1.3951911836243442\n",
      "\n",
      "W2 =  [[ 0.54805191  0.29721116  0.8073263   0.24249832  0.97482477  0.64889355\n",
      "   1.33205654  0.58502821 -0.31734847]\n",
      " [ 0.73948388  0.99224581  1.36537706 -0.186465    1.20302025  1.10486917\n",
      "   0.53695509  0.12252682 -0.04766315]] \n",
      "\n",
      "b2 =  [ 1.12492826  0.58079708 -0.72268765  1.26699966 -0.67037797 -0.16658082\n",
      " -0.393419    0.75682112  0.81948388] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2400   , loss value =  1.080149226722186\n",
      "\n",
      "W2 =  [[ 0.5374367   0.3063704   0.95337274  0.0383587   1.10629753  0.71728904\n",
      "   1.47331401  0.54159562 -0.56706491]\n",
      " [ 0.73019126  1.00935796  1.47178026 -0.32798825  1.28288699  1.16716842\n",
      "   0.58309031  0.09921102 -0.27731118]] \n",
      "\n",
      "b2 =  [ 1.17827629  0.54168092 -1.0821473   1.30315443 -1.03119997 -0.38388751\n",
      " -0.64714492  0.79149645  0.84616938] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2800   , loss value =  0.7964097044863471\n",
      "\n",
      "W2 =  [[ 0.5308798   0.31124805  1.09820565 -0.18774083  1.23905908  0.77595396\n",
      "   1.59671299  0.50236957 -0.807563  ]\n",
      " [ 0.72287371  1.0228665   1.57021971 -0.50248157  1.36999502  1.22227101\n",
      "   0.63399658  0.07725716 -0.4997626 ]] \n",
      "\n",
      "b2 =  [ 1.22525784  0.50898156 -1.41050298  1.31025967 -1.35688967 -0.58882619\n",
      " -0.88351765  0.82168229  0.89669632] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3200   , loss value =  0.5797845355581981\n",
      "\n",
      "W2 =  [[ 0.52778697  0.31304076  1.22899755 -0.40834287  1.35766736  0.82416117\n",
      "   1.69260136  0.46890404 -0.99097779]\n",
      " [ 0.71696108  1.03328163  1.66380214 -0.68873507  1.46234576  1.27251371\n",
      "   0.692027    0.05677318 -0.67417801]] \n",
      "\n",
      "b2 =  [ 1.26474648  0.48312895 -1.68486402  1.30647367 -1.62659382 -0.76629747\n",
      " -1.0848078   0.84700211  0.98485653] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3600   , loss value =  0.42897071459634545\n",
      "\n",
      "W2 =  [[ 0.52669951  0.31332333  1.34156313 -0.59513497  1.45819201  0.86476029\n",
      "   1.76426662  0.44086672 -1.12005184]\n",
      " [ 0.71218485  1.04123655  1.74946291 -0.85582366  1.55134465  1.31786003\n",
      "   0.75195629  0.0381823  -0.80256251]] \n",
      "\n",
      "b2 =  [ 1.29716665  0.463202   -1.90427541  1.31419902 -1.84135091 -0.9125752\n",
      " -1.24958149  0.8677945   1.09150251] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4000   , loss value =  0.32710828656441193\n",
      "\n",
      "W2 =  [[ 0.52650234  0.31306719  1.43722353 -0.73947335  1.54279436  0.90029589\n",
      "   1.81883961  0.41721132 -1.21317834]\n",
      " [ 0.70832869  1.04738303  1.82482449 -0.98952011  1.63152023  1.35800045\n",
      "   0.8091813   0.02162369 -0.89966127]] \n",
      "\n",
      "b2 =  [ 1.32363985  0.44780467 -2.07858853  1.34000482 -2.01164901 -1.03123727\n",
      " -1.38340389  0.88471958  1.19793567] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4400   , loss value =  0.25742214473869457\n",
      "\n",
      "W2 =  [[ 0.52663113  0.31268239  1.51871994 -0.84858035  1.61456714  0.93210394\n",
      "   1.86194752  0.39695099 -1.28405552]\n",
      " [ 0.70518651  1.0522502   1.88991156 -1.09271057  1.70159265  1.39318905\n",
      "   0.86168557  0.00695394 -0.97644459]] \n",
      "\n",
      "b2 =  [ 1.34541251  0.43567028 -2.21899172  1.37834678 -2.148691   -1.12805349\n",
      " -1.4930939   0.89853613  1.29598219] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4800   , loss value =  0.20830348393537676\n",
      "\n",
      "W2 =  [[ 0.5268544   0.31230584  1.58864839 -0.93248373  1.676084    0.96082553\n",
      "   1.89714497  0.37934475 -1.34063205]\n",
      " [ 0.70259241  1.05620486  1.94591385 -1.17298555  1.76228065  1.42398263\n",
      "   0.90903892 -0.0060667  -1.0394387 ]] \n",
      "\n",
      "b2 =  [ 1.36355698  0.42586809 -2.3343919   1.42247559 -2.26126954 -1.20823391\n",
      " -1.58442784  0.90993478  1.3836764 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5200   , loss value =  0.17256418935948803\n",
      "\n",
      "W2 =  [[ 0.52708702  0.31197379  1.64918165 -0.99892128  1.72935497  0.98685901\n",
      "   1.92663832  0.3638523  -1.38745002]\n",
      " [ 0.70042034  1.05949225  1.99429606 -1.23688162  1.81491268  1.45101537\n",
      "   0.95152274 -0.01768418 -1.09255307]] \n",
      "\n",
      "b2 =  [ 1.37890228  0.41776239 -2.43114989  1.46798997 -2.35563533 -1.27576744\n",
      " -1.66174705  0.91946703  1.46146652] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5600   , loss value =  0.14579474084929792\n",
      "\n",
      "W2 =  [[ 0.52730095  0.31168991  1.70207244 -1.05309345  1.7759471   1.01052785\n",
      "   1.95185653  0.350072   -1.42723753]\n",
      " [ 0.69857607  1.06227852  2.03641647 -1.28903332  1.86083808  1.47488464\n",
      "   0.98966615 -0.02811861 -1.13826922]] \n",
      "\n",
      "b2 =  [ 1.39206623  0.41092182 -2.51371846  1.51255302 -2.43615403 -1.33356605\n",
      " -1.72821216  0.9275498   1.53051939] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6000   , loss value =  0.12522735614793618\n",
      "\n",
      "W2 =  [[ 0.52748937  0.31144868  1.74871135 -1.09841107  1.81708386  1.03211997\n",
      "   1.97377063  0.33769869 -1.46173487]\n",
      " [ 0.69698942  1.06467913  2.07341337 -1.33258764  1.90123113  1.49610723\n",
      "   1.02403644 -0.03755592 -1.17825441]] \n",
      "\n",
      "b2 =  [ 1.40350656  0.40504843 -2.58525056  1.55507429 -2.50591165 -1.38374451\n",
      " -1.78612687  0.93449349  1.59208912] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6400   , loss value =  0.10907185671735625\n",
      "\n",
      "W2 =  [[ 0.52765294  0.31124297  1.79019518 -1.13714138  1.85372309  1.05189248\n",
      "   1.9930677   0.32649635 -1.49211403]\n",
      " [ 0.69560796  1.06677638  2.10620252 -1.36968897  1.93705587  1.51511255\n",
      "   1.05515704 -0.04614928 -1.21368154]] \n",
      "\n",
      "b2 =  [ 1.41356473  0.39993141 -2.64802488  1.59513301 -2.56713533 -1.42785448\n",
      " -1.83719165  0.94052962  1.64730965] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6800   , loss value =  0.09613556336490049\n",
      "\n",
      "W2 =  [[ 0.52779458  0.31106625  1.82738987 -1.17083079  1.88661849  1.07007141\n",
      "   2.01025     0.31627979 -1.51920068]\n",
      " [ 0.69439219  1.0686304   2.1355101  -1.40182673  1.96908639  1.53225117\n",
      "   1.08348296 -0.05402374 -1.24540613]] \n",
      "\n",
      "b2 =  [ 1.42249856  0.39541787 -2.70372448  1.63264895 -2.62146808 -1.46705226\n",
      " -1.88268209  0.94583257  1.69714533] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************************************************************\n",
      "step =  7200   , loss value =  0.08560183247005437\n",
      "\n",
      "W2 =  [[ 0.52791762  0.31091312  1.86098256 -1.20056455  1.91636736  1.08685274\n",
      "   2.02569441  0.30690175 -1.5435981 ]\n",
      " [ 0.69331199  1.07028609  2.16191098 -1.43006014  1.99794068  1.54780775\n",
      "   1.10939955 -0.06128132 -1.2740705 ]] \n",
      "\n",
      "b2 =  [ 1.43050544  0.39139437 -2.7536182   1.66770637 -2.67014739 -1.50221414\n",
      " -1.92357112  0.95053534  1.74239678] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  7600   , loss value =  0.07689746672218348\n",
      "\n",
      "W2 =  [[ 0.5280251   0.31077926  1.89152256 -1.22712561  1.94344711  1.102405\n",
      "   2.03968999  0.29824382 -1.5657604 ]\n",
      " [ 0.69234408  1.07177766  2.18586221 -1.45516061  2.02411306  1.56201365\n",
      "   1.13322987 -0.06800554 -1.30016838]] \n",
      "\n",
      "b2 =  [ 1.43773861  0.38777501 -2.79868072  1.70046235 -2.71412309 -1.53401519\n",
      " -1.96061284  0.95474071  1.7837234 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8000   , loss value =  0.06961105971650276\n",
      "\n",
      "W2 =  [[ 0.52811962  0.31066125  1.91945279 -1.25109332  1.96824274  1.11687253\n",
      "   2.05246258  0.29020967 -1.58603781]\n",
      " [ 0.69147028  1.07313162  2.2077299  -1.47770276  2.04800125  1.57505777\n",
      "   1.155244   -0.0742652  -1.32408688]] \n",
      "\n",
      "b2 =  [ 1.44431872  0.38449345 -2.83967345  1.73109972 -2.75413678 -1.56298366\n",
      " -1.99440048  0.95852919  1.82166794] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8400   , loss value =  0.06344133429643532\n",
      "\n",
      "W2 =  [[ 0.5282033   0.31055639  1.94513352 -1.27290631  1.99106764  1.13037883\n",
      "   2.06419147  0.28272016 -1.604706  ]\n",
      " [ 0.69067617  1.07436887  2.2278099  -1.49812344  2.06992772  1.58709525\n",
      "   1.1756681  -0.08011738 -1.34613461]] \n",
      "\n",
      "b2 =  [ 1.45034197  0.38149768 -2.87720024  1.7598035  -2.79077633 -1.58953883\n",
      " -2.02540723  0.96196463  1.8566787 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8800   , loss value =  0.058163628617267385\n",
      "\n",
      "W2 =  [[ 0.52827791  0.31046254  1.96886049 -1.29290348  2.01217917  1.14302969\n",
      "   2.075021    0.27570966 -1.62198568]\n",
      " [ 0.68995018  1.07550612  2.24634347 -1.51676106  2.0901561   1.59825445\n",
      "   1.19469229 -0.08560978 -1.36656122]] \n",
      "\n",
      "b2 =  [ 1.45588597  0.37874624 -2.91174658  1.78674969 -2.82451424 -1.61401791\n",
      " -2.0540153   0.9650983   1.88912785] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9200   , loss value =  0.05360764821150469\n",
      "\n",
      "W2 =  [[ 0.52834486  0.31037799  1.99087849 -1.31135143  2.03179061  1.15491603\n",
      "   2.08506882  0.26912322 -1.63805621]\n",
      " [ 0.68928294  1.07655689  2.26352913 -1.53388209  2.10890377  1.60864234\n",
      "   1.21247714 -0.09078254 -1.38557123]] \n",
      "\n",
      "b2 =  [ 1.4610141   0.37620569 -2.94370757  1.81210044 -2.85573493 -1.63669539\n",
      " -2.08053702  0.96797182  1.9193263 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9600   , loss value =  0.04964238130602347\n",
      "\n",
      "W2 =  [[ 0.52840531  0.31030134  2.01139188 -1.3284633   2.05008007  1.16611617\n",
      "   2.09443192  0.2629145  -1.65306521]\n",
      " [ 0.68866677  1.07753227  2.2795317  -1.5496996   2.12635147  1.61834869\n",
      "   1.22915903 -0.09566973 -1.40333408]] \n",
      "\n",
      "b2 =  [ 1.46577857  0.3738487  -2.97340831  1.83600259 -2.88475471 -1.65779714\n",
      " -2.10523027  0.97061932  1.94753547] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  10000   , loss value =  0.046165670744055795\n",
      "\n",
      "W2 =  [[ 0.5284602   0.31023147  2.03057258 -1.34441189  2.06719757  1.17669792\n",
      "   2.10319102  0.25704409 -1.66713553]\n",
      " [ 0.6880953   1.07844142  2.29448915 -1.56438618  2.14265067  1.62744939\n",
      "   1.24485441 -0.10030041 -1.41999159]] \n",
      "\n",
      "b2 =  [ 1.47022288  0.3716527  -3.00111907  1.85858787 -2.91183649 -1.6775109\n",
      " -2.12831005  0.97306907  1.9739766 ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AND Gate 객체 생성 및 training\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([0, 0, 0, 1])\n",
    "\n",
    "and_obj = LogicGate(\"AND\", xdata, tdata)\n",
    "\n",
    "and_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([5.56577322e-05]), 0)\n",
      "(array([0.01213451]), 0)\n",
      "(array([0.01225424]), 0)\n",
      "(array([0.97865927]), 1)\n"
     ]
    }
   ],
   "source": [
    "# AND Gate prediction\n",
    "\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(and_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR object is created\n",
      "Initial loss value =  3.9423339785817038\n",
      "\n",
      "*****************************************************************************\n",
      "step =  0   , loss value =  3.9012113672303395\n",
      "\n",
      "W2 =  [[0.69938422 0.18218233 0.9230102  0.35352237 0.44683821 0.66167196\n",
      "  0.12547001 0.01577447 0.05249773]\n",
      " [0.35263152 0.19439866 0.98026817 0.97581691 0.2530963  0.34564395\n",
      "  0.22636684 0.73427797 0.4612407 ]] \n",
      "\n",
      "b2 =  [0.32376135 0.67583941 0.46103227 0.10154547 0.45119337 0.86862795\n",
      " 0.78690648 0.51513479 0.16699078] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  400   , loss value =  1.9990691790628714\n",
      "\n",
      "W2 =  [[0.68963341 0.30514712 0.8842408  0.46877015 0.55735775 0.7064195\n",
      "  0.26546201 0.17121991 0.1734417 ]\n",
      " [0.34271349 0.30920301 0.94541523 1.06993804 0.3605529  0.39218208\n",
      "  0.35433209 0.85808437 0.56972814]] \n",
      "\n",
      "b2 =  [ 0.32018499  0.52964898  0.55183669 -0.04229879  0.3079237   0.76640182\n",
      "  0.62195179  0.32407493  0.04687974] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  800   , loss value =  1.811158952462448\n",
      "\n",
      "W2 =  [[0.70081644 0.40872875 0.87791318 0.68122437 0.68853851 0.7529421\n",
      "  0.38253034 0.35498574 0.31349935]\n",
      " [0.35384707 0.40446074 0.93976968 1.23875209 0.48650486 0.43998153\n",
      "  0.45954959 1.00024123 0.6921376 ]] \n",
      "\n",
      "b2 =  [ 0.31110422  0.46421567  0.56310675 -0.21076849  0.21035661  0.7093856\n",
      "  0.54330077  0.18311127 -0.01967726] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1200   , loss value =  1.5693710582329432\n",
      "\n",
      "W2 =  [[0.72408346 0.48536128 0.89825655 0.97321224 0.83072811 0.79194616\n",
      "  0.46884226 0.55621073 0.46474728]\n",
      " [0.37650265 0.47290764 0.95703746 1.46193834 0.61948015 0.47905793\n",
      "  0.53477046 1.14984102 0.81904983]] \n",
      "\n",
      "b2 =  [ 2.90580180e-01  4.04842586e-01  5.25546635e-01 -4.60302802e-01\n",
      "  8.23209998e-02  6.56751175e-01  4.71488066e-01  6.25039908e-04\n",
      " -1.08600396e-01] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1600   , loss value =  1.2766117193594946\n",
      "\n",
      "W2 =  [[0.74715362 0.53931524 0.93164663 1.32689831 0.98266326 0.8191955\n",
      "  0.53043437 0.77629049 0.62573828]\n",
      " [0.3983724  0.51952049 0.98445489 1.72280176 0.75735664 0.50561533\n",
      "  0.5866157  1.30760589 0.94833093]] \n",
      "\n",
      "b2 =  [ 0.26840627  0.35699095  0.46296855 -0.74569759 -0.0720032   0.61724804\n",
      "  0.41278922 -0.21436848 -0.21856398] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2000   , loss value =  0.9795564556814604\n",
      "\n",
      "W2 =  [[0.76321375 0.57297138 0.96829729 1.70281059 1.13619021 0.83317134\n",
      "  0.5704899  1.00379782 0.78658158]\n",
      " [0.41331656 0.54787649 1.01387638 1.99539076 0.8939123  0.51899314\n",
      "  0.61946055 1.4676699  1.07343061]] \n",
      "\n",
      "b2 =  [ 0.25179485  0.32424233  0.39361877 -1.00124504 -0.23605085  0.59588972\n",
      "  0.37101233 -0.43344229 -0.33828267] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2400   , loss value =  0.728203327155813\n",
      "\n",
      "W2 =  [[0.7708702  0.59047412 1.00207301 2.05326798 1.28021987 0.83602599\n",
      "  0.59342606 1.22008866 0.93530343]\n",
      " [0.42043836 0.56254263 1.04098392 2.25326708 1.02221705 0.52172224\n",
      "  0.63815642 1.62110444 1.1883463 ]] \n",
      "\n",
      "b2 =  [ 0.24336684  0.30597337  0.32901138 -1.19873065 -0.38976956  0.59135911\n",
      "  0.34542048 -0.62698392 -0.45319215] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2800   , loss value =  0.5408713066634828\n",
      "\n",
      "W2 =  [[0.77208364 0.59719238 1.03057604 2.35002101 1.40726639 0.83179407\n",
      "  0.60471999 1.41143817 1.06483958]\n",
      " [0.42157901 0.56823918 1.06427554 2.48031335 1.13760765 0.5175736\n",
      "  0.64747483 1.76062903 1.28996568]] \n",
      "\n",
      "b2 =  [ 0.24197342  0.29855672  0.27373629 -1.34621575 -0.52124116  0.59846623\n",
      "  0.33210917 -0.78263195 -0.55400368] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3200   , loss value =  0.4095388020499505\n",
      "\n",
      "W2 =  [[0.7694358  0.59768346 1.05386497 2.58991974 1.51567159 0.82399503\n",
      "  0.60904755 1.57406324 1.17436728]\n",
      " [0.419007   0.56865818 1.08377627 2.67236792 1.23862331 0.50974975\n",
      "  0.65111493 1.88314077 1.37795392]] \n",
      "\n",
      "b2 =  [ 0.2452203   0.29800374  0.22797109 -1.4585712  -0.62857353  0.61198452\n",
      "  0.32678136 -0.90320138 -0.63840119] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3600   , loss value =  0.31859742508632966\n",
      "\n",
      "W2 =  [[0.76480782 0.59489701 1.07287816 2.78206588 1.60731501 0.81480285\n",
      "  0.6094945  1.71052017 1.26641036]\n",
      " [0.4144193  0.56619145 1.10006671 2.83251427 1.32610839 0.50031489\n",
      "  0.65149545 1.98901691 1.45363984]] \n",
      "\n",
      "b2 =  [ 0.2510831   0.30136506  0.19021311 -1.54673993 -0.71509842  0.62835729\n",
      "  0.32621859 -0.99663275 -0.70801977] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4000   , loss value =  0.2547493986041289\n",
      "\n",
      "W2 =  [[0.75929923 0.59049561 1.08860065 2.93741691 1.68511014 0.80533625\n",
      "  0.60784869 1.82533983 1.34425668]\n",
      " [0.40885986 0.56223365 1.11379665 2.96623726 1.40188728 0.49040766\n",
      "  0.65005569 2.08028231 1.51892476]] \n",
      "\n",
      "b2 =  [ 0.25825306  0.30681439  0.15875431 -1.61782097 -0.78526217  0.64558767\n",
      "  0.32838627 -1.0703345  -0.76561734] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4400   , loss value =  0.20881844625532142\n",
      "\n",
      "W2 =  [[0.75349533 0.58536559 1.10182303 3.06507326 1.7518066  0.79611099\n",
      "  0.60509813 1.92289014 1.4108502 ]\n",
      " [0.40291649 0.55756006 1.12551913 3.07889964 1.46791421 0.48059945\n",
      "  0.64761969 2.15932166 1.57566179]] \n",
      "\n",
      "b2 =  [ 0.26597257  0.31330213  0.1321644  -1.67646222 -0.84294364  0.66266615\n",
      "  0.33208201 -1.12981968 -0.81378499] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4800   , loss value =  0.1748792708999075\n",
      "\n",
      "W2 =  [[0.74769391 0.5799715  1.11313118 3.17181667 1.8096538  0.78733927\n",
      "  0.60178557 2.00675626 1.46853667]\n",
      " [0.3969061  0.55259448 1.13566438 3.17493826 1.52592169 0.47115415\n",
      "  0.64465597 2.22831355 1.62542902]] \n",
      "\n",
      "b2 =  [ 0.27382384  0.32024064  0.10935206 -1.72579796 -0.89112247  0.67912299\n",
      "  0.33660774 -1.17892215 -0.85460456] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5200   , loss value =  0.14914727974308756\n",
      "\n",
      "W2 =  [[0.74204058 0.57455532 1.12295094 3.26254943 1.86040235 0.77908866\n",
      "  0.59821213 2.07972146 1.51911312]\n",
      " [0.3909942  0.54756711 1.1445575  3.25780606 1.57733664 0.46217802\n",
      "  0.64143275 2.28907197 1.66949869]] \n",
      "\n",
      "b2 =  [ 0.28158315  0.32730353  0.08950687 -1.76800304 -0.93199457  0.69476627\n",
      "  0.34155691 -1.22027834 -0.88966161] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5600   , loss value =  0.12917596666001427\n",
      "\n",
      "W2 =  [[0.73660165 0.56924136 1.13159308 3.34081294 1.90539561 0.77136045\n",
      "  0.59454687 2.14391139 1.56394444]\n",
      " [0.38526328 0.54260181 1.15244313 3.33013732 1.62330102 0.45369895\n",
      "  0.63810515 2.3430531  1.70887585]] \n",
      "\n",
      "b2 =  [ 0.28913504  0.33431082  0.07202773 -1.80462602 -0.96716572  0.70954275\n",
      "  0.34669055 -1.25572143 -0.9201463 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6000   , loss value =  0.11335021947741016\n",
      "\n",
      "W2 =  [[0.73140218 0.56409097 1.13928735 3.40919448 1.94566587 0.7641273\n",
      "  0.59088531 2.2009503  1.60407209]\n",
      " [0.37975053 0.53776345 1.15950669 3.39393835 1.6647211  0.44570716\n",
      "  0.63476342 2.39141177 1.74435141]] \n",
      "\n",
      "b2 =  [ 0.29642419  0.34116512  0.0564645  -1.83679563 -0.99781802  0.72346627\n",
      "  0.35186711 -1.28655108 -0.94695383] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6400   , loss value =  0.1005780902797395\n",
      "\n",
      "W2 =  [[0.726446   0.55913144 1.14620646 3.46961428 1.98201297 0.75735114\n",
      "  0.58728117 2.25208911 1.64029896]\n",
      " [0.37446854 0.53308387 1.16589037 3.45074749 1.70231709 0.43817595\n",
      "  0.63145999 2.43506341 1.77655022]] \n",
      "\n",
      "b2 =  [ 0.30342862  0.34781614  0.04247548 -1.86535234 -1.02483268  0.73658131\n",
      "  0.35700267 -1.31370903 -0.97076381] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6800   , loss value =  0.09010353449162915\n",
      "\n",
      "W2 =  [[0.72172622 0.55437149 1.15248241 3.52352178 2.01506351 0.75099156\n",
      "  0.58376389 2.29830192 1.6732517 ]\n",
      " [0.36941659 0.52857626 1.17170463 3.50175651 1.73666486 0.4310721\n",
      "  0.62822478 2.47473738 1.80596975]] \n",
      "\n",
      "b2 =  [ 0.31014481  0.3542407   0.02979735 -1.89093413 -1.04887642  0.74894445\n",
      "  0.36204798 -1.33789245 -0.9920986 ] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************************************************************\n",
      "step =  7200   , loss value =  0.0813911017531977\n",
      "\n",
      "W2 =  [[0.71723088 0.54980981 1.15821777 3.57202935 2.04531422 0.74500967\n",
      "  0.58034863 2.34035643 1.70342575]\n",
      " [0.36458706 0.52424329 1.17703651 3.54789962 1.76822868 0.42436107\n",
      "  0.62507418 2.51101933 1.83300981]] \n",
      "\n",
      "b2 =  [ 0.31657922  0.36043127  0.01822418 -1.9140339  -1.07046141  0.76061508\n",
      "  0.366975   -1.35962803 -1.01136495] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  7600   , loss value =  0.07405353647064356\n",
      "\n",
      "W2 =  [[0.71294594 0.54543981 1.16349346 3.61600415 2.07316363 0.73936957\n",
      "  0.57704202 2.378865   1.73121776]\n",
      " [0.35996894 0.52008174 1.18195544 3.58991795 1.79738626 0.41800958\n",
      "  0.6220163  2.54438368 1.85799487]] \n",
      "\n",
      "b2 =  [ 0.3227435   0.36638933  0.00759263 -1.93503846 -1.08998688  0.77165086\n",
      "  0.37176882 -1.37932107 -1.02888379] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8000   , loss value =  0.0678053320554458\n",
      "\n",
      "W2 =  [[0.70885689 0.54125228 1.16837421 3.65613206 2.09893512 0.73403895\n",
      "  0.57384563 2.41432183 1.75694911]\n",
      " [0.35554981 0.51608527 1.18651756 3.62840636 1.82444773 0.41198663\n",
      "  0.61905418 2.57521832 1.88119086]] \n",
      "\n",
      "b2 =  [ 0.32865173  0.3721214  -0.00222855 -1.9542558  -1.10776839  0.78210569\n",
      "  0.3764227  -1.39728874 -1.04491147] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8400   , loss value =  0.062432282789431914\n",
      "\n",
      "W2 =  [[0.70494962 0.5372369  1.17291249 3.69296283 2.12289392 0.72898895\n",
      "  0.57075803 2.44713012 1.78088305]\n",
      " [0.35131695 0.51224595 1.1907687  3.66384761 1.84967005 0.40626397\n",
      "  0.6161878  2.60384323 1.90281777]] \n",
      "\n",
      "b2 =  [ 0.33431888  0.37763672 -0.01134612 -1.9719343  -1.12405857  0.79202891\n",
      "  0.38093502 -1.41378303 -1.05965523] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8800   , loss value =  0.05777110141840976\n",
      "\n",
      "W2 =  [[0.70121077 0.53338312 1.17715132 3.72694247 2.14525974 0.72419402\n",
      "  0.56777605 2.47762222 1.80323747]\n",
      " [0.34725795 0.50855522 1.19474676 3.69663759 1.87326797 0.40081606\n",
      "  0.61341526 2.63052469 1.92305923]] \n",
      "\n",
      "b2 =  [ 0.33975987  0.3829458  -0.01984788 -1.98827664 -1.13906206  0.80146521\n",
      "  0.3853073  -1.42900691 -1.07328438] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9200   , loss value =  0.05369550254780533\n",
      "\n",
      "W2 =  [[0.69762794 0.52968062 1.18112634 3.7584369  2.1662163  0.71963151\n",
      "  0.56489554 2.50607465 1.82419444]\n",
      " [0.34336102 0.50500443 1.19848331 3.72710408 1.89542239 0.39561999\n",
      "  0.61073356 2.65548615 1.9420698 ]] \n",
      "\n",
      "b2 =  [ 0.34498912  0.38805964 -0.02780679 -2.00344997 -1.1529465   0.81045481\n",
      "  0.38954301 -1.44312586 -1.08593867] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9600   , loss value =  0.050106523579853096\n",
      "\n",
      "W2 =  [[0.69418973 0.52611955 1.18486737 3.78774931 2.18591849 0.7152814\n",
      "  0.56211193 2.53271952 1.84390738]\n",
      " [0.33961511 0.50158512 1.20200493 3.7555209  1.91628689 0.39065525\n",
      "  0.60813913 2.67891651 1.95998057]] \n",
      "\n",
      "b2 =  [ 0.35002026  0.39298916 -0.035284   -2.01759351 -1.16585052  0.81903381\n",
      "  0.39364674 -1.45627633 -1.09773453] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  10000   , loss value =  0.04692567634641475\n",
      "\n",
      "W2 =  [[0.69088574 0.52269066 1.18839959 3.81513333 2.20449796 0.71112592\n",
      "  0.55942044 2.55775326 1.86250665]\n",
      " [0.33601    0.49828923 1.20533418 3.78211869 1.93599278 0.38590344\n",
      "  0.60562808 2.70097667 1.97690357]] \n",
      "\n",
      "b2 =  [ 0.35486606  0.39774497 -0.04233125 -2.03082419 -1.17788988  0.82723461\n",
      "  0.39762367 -1.46857196 -1.10876978] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OR Gate 객체 생성 및 training\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([0, 1, 1, 1])\n",
    "\n",
    "or_obj = LogicGate(\"OR\", xdata, tdata)\n",
    "\n",
    "or_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.02756317]), 0)\n",
      "(array([0.99113129]), 1)\n",
      "(array([0.99066075]), 1)\n",
      "(array([0.99931572]), 1)\n"
     ]
    }
   ],
   "source": [
    "# OR Gate prediction\n",
    "\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(or_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND object is created\n",
      "Initial loss value =  6.366864371766156\n",
      "\n",
      "*****************************************************************************\n",
      "step =  0   , loss value =  6.294157734556809\n",
      "\n",
      "W2 =  [[0.26212023 0.57671022 0.91996226 0.24415119 0.95847566 0.47253312\n",
      "  0.48583167 0.75136002 0.12224776]\n",
      " [0.51456366 0.38095801 0.63979229 0.51827438 0.0657543  0.18446193\n",
      "  0.76268146 0.41449544 0.85756536]] \n",
      "\n",
      "b2 =  [0.09771477 0.55055759 0.66090974 0.84625164 0.52266281 0.47247972\n",
      " 0.8914636  0.76011667 0.35722047] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  400   , loss value =  2.3309606223381545\n",
      "\n",
      "W2 =  [[ 0.13634083  0.51265663  0.90935237  0.16221986  0.79503654  0.42533285\n",
      "   0.42727776  0.65919948 -0.03965852]\n",
      " [ 0.38724943  0.31822366  0.62710612  0.43239162 -0.0763056   0.13776867\n",
      "   0.6994884   0.32953714  0.68118379]] \n",
      "\n",
      "b2 =  [0.04933343 0.52237886 0.61760654 0.82667101 0.50739224 0.43658834\n",
      " 0.89858312 0.76576289 0.32640884] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  800   , loss value =  2.2715011614405887\n",
      "\n",
      "W2 =  [[ 0.09053646  0.51173101  0.93998226  0.10981102  0.70211228  0.42435374\n",
      "   0.40900191  0.61977873 -0.12404737]\n",
      " [ 0.34004201  0.317369    0.65043058  0.37390523 -0.1498797   0.13685101\n",
      "   0.67683212  0.29624682  0.58332871]] \n",
      "\n",
      "b2 =  [0.06270694 0.52316433 0.52927497 0.86067326 0.55312774 0.43705156\n",
      " 0.93604941 0.81183702 0.36312263] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1200   , loss value =  2.2033051210481833\n",
      "\n",
      "W2 =  [[ 0.0564283   0.53434864  0.99547225  0.03617879  0.60989247  0.43242689\n",
      "   0.39658855  0.58974479 -0.21118713]\n",
      " [ 0.30463291  0.3389247   0.69349613  0.29166679 -0.22590582  0.14453676\n",
      "   0.66119328  0.2703418   0.48350058]] \n",
      "\n",
      "b2 =  [0.07114226 0.50473715 0.36492674 0.89666848 0.58586708 0.43340793\n",
      " 0.96030273 0.84353446 0.38907329] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1600   , loss value =  2.097538295039694\n",
      "\n",
      "W2 =  [[ 0.02691966  0.58269594  1.08176533 -0.07299696  0.50063039  0.45445289\n",
      "   0.39067601  0.56896099 -0.3229207 ]\n",
      " [ 0.27354387  0.38587837  0.76371789  0.16934127 -0.32001324  0.16583491\n",
      "   0.65349743  0.25195443  0.3563463 ]] \n",
      "\n",
      "b2 =  [0.07751563 0.46157326 0.09831972 0.93032875 0.61110116 0.42318914\n",
      " 0.97169244 0.86385824 0.40983321] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2000   , loss value =  1.9047195116191238\n",
      "\n",
      "W2 =  [[-0.002686    0.65406158  1.20188123 -0.24387367  0.35054235  0.4936262\n",
      "   0.39137319  0.55754493 -0.48754273]\n",
      " [ 0.24149253  0.45790342  0.87375744 -0.0235534  -0.45655481  0.2047881\n",
      "   0.65455802  0.241501    0.16928495]] \n",
      "\n",
      "b2 =  [ 0.08312336  0.38583103 -0.2902588   0.95001441  0.62732672  0.40336195\n",
      "  0.97020766  0.87450636  0.42586419] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2400   , loss value =  1.5749347798002533\n",
      "\n",
      "W2 =  [[-0.03369742  0.73502484  1.34258098 -0.50326217  0.140943    0.54663799\n",
      "   0.3970481   0.55492777 -0.71457183]\n",
      " [ 0.20645532  0.54603079  1.03715566 -0.3206764  -0.66127469  0.25996214\n",
      "   0.6639194   0.23900827 -0.09031802]] \n",
      "\n",
      "b2 =  [ 0.08827343  0.27503615 -0.77458994  0.94378608  0.62950753  0.37182046\n",
      "  0.95703352  0.87691428  0.44677568] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2800   , loss value =  1.172496436600735\n",
      "\n",
      "W2 =  [[-0.06462288  0.80494606  1.47618757 -0.7987565  -0.09814032  0.60061846\n",
      "   0.40372042  0.55778376 -0.94447194]\n",
      " [ 0.17011457  0.63026824  1.24325396 -0.66867232 -0.91512954  0.31865681\n",
      "   0.67746392  0.24185508 -0.35662602]] \n",
      "\n",
      "b2 =  [ 0.09303332  0.14329872 -1.27185204  0.9601389   0.63585601  0.33131782\n",
      "  0.93734884  0.87413567  0.51256086] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3200   , loss value =  0.8432510560452725\n",
      "\n",
      "W2 =  [[-0.09422092  0.85812683  1.6061524  -1.02449168 -0.29828668  0.64660963\n",
      "   0.40912797  0.56229319 -1.12015153]\n",
      " [ 0.13553016  0.69642989  1.45620911 -0.94238285 -1.14503356  0.36791365\n",
      "   0.69022335  0.24615928 -0.55806358]] \n",
      "\n",
      "b2 =  [ 0.09727081  0.01297205 -1.70713036  1.06462524  0.68251995  0.28883222\n",
      "  0.91747263  0.86960187  0.63468283] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3600   , loss value =  0.6136752925345099\n",
      "\n",
      "W2 =  [[-0.12182933  0.90135819  1.74209549 -1.17932442 -0.44165717  0.68491884\n",
      "   0.41366308  0.56713418 -1.24852017]\n",
      " [ 0.10468297  0.74566119  1.64805582 -1.12756565 -1.317523    0.40575441\n",
      "   0.70075004  0.25034219 -0.69719916]] \n",
      "\n",
      "b2 =  [ 0.10069313 -0.10400979 -2.05858908  1.22163822  0.76559989  0.24905543\n",
      "  0.89993528  0.86479173  0.77995994] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4000   , loss value =  0.45727196347128246\n",
      "\n",
      "W2 =  [[-0.14676059  0.93857546  1.87379266 -1.29422364 -0.54458571  0.71701543\n",
      "   0.41767938  0.57194546 -1.34685009]\n",
      " [ 0.0780499   0.78333469  1.80930265 -1.25792295 -1.44216412  0.43474448\n",
      "   0.70932833  0.25412987 -0.79725756]] \n",
      "\n",
      "b2 =  [ 0.10331288 -0.20484146 -2.33736104  1.38431283  0.86169766  0.21360218\n",
      "  0.88498264  0.86014799  0.92183122] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4400   , loss value =  0.35026239641714035\n",
      "\n",
      "W2 =  [[-0.16872017  0.97097992  1.99195143 -1.38582048 -0.62222388  0.74392188\n",
      "   0.42123794  0.57652148 -1.42515494]\n",
      " [ 0.05529577  0.81349944  1.94204353 -1.35653612 -1.5343962   0.45746948\n",
      "   0.71643134  0.25751511 -0.87419301]] \n",
      "\n",
      "b2 =  [ 0.10530248 -0.29047643 -2.56010971  1.53255706  0.95586486  0.18264536\n",
      "  0.87230268  0.85584243  1.04941384] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4800   , loss value =  0.2758824709591481\n",
      "\n",
      "W2 =  [[-0.18785654  0.99921413  2.09416496 -1.46171731 -0.68366896  0.76656359\n",
      "   0.42436596  0.58075784 -1.48912044]\n",
      " [ 0.03583016  0.83857007  2.05160112 -1.43535881 -1.60516501  0.47576025\n",
      "   0.72242216  0.26053503 -0.93660502]] \n",
      "\n",
      "b2 =  [ 0.10684082 -0.36317117 -2.74079501  1.6617502   1.04223062  0.15574731\n",
      "  0.86149523  0.85192859  1.16064063] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5200   , loss value =  0.22297669659108982\n",
      "\n",
      "W2 =  [[-0.20452962  1.02389373  2.18168689 -1.52601078 -0.73417461  0.78578045\n",
      "   0.42711061  0.5846278  -1.54240901]\n",
      " [ 0.01905891  0.85997023  2.1430543  -1.50070406 -1.66132918  0.49083795\n",
      "   0.72755787  0.2632341  -0.98910079]] \n",
      "\n",
      "b2 =  [ 0.10806474 -0.42531682 -2.88989662  1.77305735  1.11949564  0.13229367\n",
      "  0.85219548  0.84839744  1.25688879] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5600   , loss value =  0.18435964059597432\n",
      "\n",
      "W2 =  [[-0.21913496  1.04560259  2.2568139  -1.5813322  -0.77689787  0.80227279\n",
      "   0.42952768  0.58814701 -1.58756151]\n",
      " [ 0.00447102  0.87859421  2.22045532 -1.55623657 -1.70718599  0.50352488\n",
      "   0.73202304  0.26565596 -1.03434425]] \n",
      "\n",
      "b2 =  [ 0.10906836 -0.47898653 -3.01503741  1.86915891  1.18814938  0.1116925\n",
      "  0.84410451  0.84521324  1.34042572] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6000   , loss value =  0.1554414583522052\n",
      "\n",
      "W2 =  [[-0.23202802  1.06484833  2.32180026 -1.62954495 -0.81383836  0.81659358\n",
      "   0.43167002  0.59134843 -1.62639812]\n",
      " [-0.00834607  0.89504417  2.28687063 -1.60429394 -1.74551158  0.51438849\n",
      "   0.7359533   0.2678403  -1.07402059]] \n",
      "\n",
      "b2 =  [ 0.10991439 -0.5258441  -3.12172733  1.95274832  1.24922383  0.09343968\n",
      "  0.83698754  0.84233313  1.4134568 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6400   , loss value =  0.13326427379354977\n",
      "\n",
      "W2 =  [[-0.24350452  1.08205011  2.37854641 -1.67202958 -0.84632723  0.82916919\n",
      "   0.43358302  0.59426912 -1.66024719]\n",
      " [-0.01971715  0.9097479   2.34459129 -1.64647628 -1.77816486  0.52383052\n",
      "   0.73945025  0.26982158 -1.10927793]] \n",
      "\n",
      "b2 =  [ 0.11064476 -0.56718655 -3.21397285  2.02611681  1.30380721  0.07712618\n",
      "  0.83066283  0.8397159   1.47785476] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************************************************************\n",
      "step =  6800   , loss value =  0.1158872510858707\n",
      "\n",
      "W2 =  [[-0.25380315  1.09754623  2.42857234 -1.70983345 -0.87528988  0.84032664\n",
      "   0.43530406  0.59694442 -1.69009372]\n",
      " [-0.02989628  0.92302121  2.39533441 -1.68393359 -1.80643325  0.53214223\n",
      "   0.74259124  0.27162896 -1.14094178]] \n",
      "\n",
      "b2 =  [ 0.11128794 -0.60401778 -3.29472282  2.09110844  1.35287917  0.06242588\n",
      "  0.82498975  0.83732505  1.53513479] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  7200   , loss value =  0.10200868362555604\n",
      "\n",
      "W2 =  [[-0.26311475  1.11160778  2.47307338 -1.74376404 -0.90139369  0.85031781\n",
      "   0.43686345  0.59940579 -1.7166797 ]\n",
      " [-0.03908262  0.93510391  2.44039976 -1.71752107 -1.83123564  0.53953946\n",
      "   0.74543604  0.27328681 -1.16962896]] \n",
      "\n",
      "b2 =  [ 0.11186372 -0.63711737 -3.36618034  2.1491812   1.39727168  0.0490795\n",
      "  0.81985881  0.83512946  1.58650311] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  7600   , loss value =  0.09073535427809595\n",
      "\n",
      "W2 =  [[-0.27159198  1.12445232  2.51298804 -1.77445251 -0.92513493  0.85933849\n",
      "   0.43828565  0.60168042 -1.74057286]\n",
      " [-0.04743348  0.94618212  2.48078365 -1.74789119 -1.85324538  0.54618531\n",
      "   0.74803145  0.27481538 -1.19581351]] \n",
      "\n",
      "b2 =  [ 0.1123862  -0.66709561 -3.43001749  2.20148539  1.43767522  0.03688012\n",
      "  0.81518394  0.83310295  1.63291793] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8000   , loss value =  0.08144054737767459\n",
      "\n",
      "W2 =  [[-0.27935763  1.13625539  2.54905702 -1.80239831 -0.94689233  0.86754254\n",
      "   0.43959048  0.60379151 -1.76221413]\n",
      " [-0.05507422  0.95640289  2.51726014 -1.77555185 -1.87296744  0.55220526\n",
      "   0.75041464  0.27623152 -1.21986773]] \n",
      "\n",
      "b2 =  [ 0.11286564 -0.69443518 -3.48752311  2.24893296  1.4746585   0.02566138\n",
      "  0.81089673  0.83122364  1.67514377] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8400   , loss value =  0.07367520703347454\n",
      "\n",
      "W2 =  [[-0.28651119  1.14715973  2.58186982 -1.82800143 -0.96696127  0.87505226\n",
      "   0.4407941   0.60575871 -1.78195087]\n",
      " [-0.06210579  0.96588421  2.55043867 -1.8009051  -1.89078825  0.55769748\n",
      "   0.75261547  0.27754927 -1.24208919]] \n",
      "\n",
      "b2 =  [ 0.11330967 -0.71952205 -3.53970544  2.29225266  1.50868985  0.01528838\n",
      "  0.80694223  0.82947323  1.71379508] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8800   , loss value =  0.06711125553058334\n",
      "\n",
      "W2 =  [[-0.29313399  1.15728239  2.61190007 -1.85158569 -0.98557645  0.881966\n",
      "   0.44190976  0.60759872 -1.80006037]\n",
      " [-0.06861027  0.97472202  2.5808052  -1.82427385 -1.90700887  0.56273984\n",
      "   0.75465821  0.2787804  -1.26271918]] \n",
      "\n",
      "b2 =  [ 0.11372412 -0.7426682  -3.58736412  2.33203232  1.5401563   0.0056507\n",
      "  0.8032758   0.82783635  1.74937003] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9200   , loss value =  0.06150468219040367\n",
      "\n",
      "W2 =  [[-0.29929309  1.16672017  2.63953209 -1.87341606 -1.00292738  0.88836372\n",
      "   0.44294843  0.60932573 -1.81676671]\n",
      " [-0.07465507  0.98299523  2.60875187 -1.84592074 -1.92186756  0.567395\n",
      "   0.75656277  0.27993483 -1.2819559 ]] \n",
      "\n",
      "b2 =  [ 1.14113485e-01 -7.64128477e-01 -3.63114154e+00  2.36875060e+00\n",
      "  1.56937946e+00 -3.34286167e-03  7.99860806e-01  8.26300036e-01\n",
      "  1.78227614e+00] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9600   , loss value =  0.0566710143351163\n",
      "\n",
      "W2 =  [[-0.30504426  1.17555383  2.66508072 -1.89371141 -1.01916923  0.89431113\n",
      "   0.44391925  0.61095184 -1.83225301]\n",
      " [-0.08029609  0.99076947  2.63459866 -1.8660618  -1.93555557  0.57171396\n",
      "   0.75834572  0.28102096 -1.29996389]] \n",
      "\n",
      "b2 =  [ 0.1144813  -0.78411312 -3.67155977  2.402801    1.59662826 -0.01176828\n",
      "  0.79666688  0.82485331  1.81284981] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  10000   , loss value =  0.05246869579490189\n",
      "\n",
      "W2 =  [[-0.31043427  1.18385126  2.68880632 -1.91265419 -1.03443059  0.89986269\n",
      "   0.44482992  0.61248745 -1.84667047]\n",
      " [-0.08558007  0.99809983  2.65860936 -1.88487658 -1.9482284   0.57573871\n",
      "   0.76002088  0.28204596 -1.31688113]] \n",
      "\n",
      "b2 =  [ 0.1148304  -0.80279718 -3.70904773  2.43450993  1.62212906 -0.01968939\n",
      "  0.79366862  0.82348678  1.8413711 ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NAND Gate 객체 생성 및 training\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([1, 1, 1, 0])\n",
    "\n",
    "nand_obj = LogicGate(\"NAND\", xdata, tdata)\n",
    "\n",
    "nand_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.99993455]), 1)\n",
      "(array([0.98687471]), 1)\n",
      "(array([0.98700065]), 1)\n",
      "(array([0.02576904]), 0)\n"
     ]
    }
   ],
   "source": [
    "# NAND Gate prediction\n",
    "\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(nand_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR object is created\n",
      "Initial loss value =  6.5538693869156965\n",
      "\n",
      "*****************************************************************************\n",
      "step =  0   , loss value =  6.367475142074479\n",
      "\n",
      "W2 =  [[0.45290599 0.20554626 0.45828699 0.98708637 0.64928909 0.32432905\n",
      "  0.82113284 0.74575112 0.38692808]\n",
      " [0.50548379 0.04382995 0.25967212 0.93699938 0.50442005 0.1931032\n",
      "  0.78911421 0.48701335 0.95413677]] \n",
      "\n",
      "b2 =  [0.14849616 0.62098052 0.54910219 0.19563137 0.08073352 0.54975914\n",
      " 0.70809689 0.5189335  0.26136182] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  400   , loss value =  2.770488221197539\n",
      "\n",
      "W2 =  [[0.43926697 0.20146092 0.4481555  0.97334733 0.6420904  0.31233223\n",
      "  0.8378266  0.72484507 0.39380283]\n",
      " [0.49405993 0.0371565  0.24834376 0.92301908 0.49799956 0.18133493\n",
      "  0.80604192 0.45417391 0.94914531]] \n",
      "\n",
      "b2 =  [0.14307663 0.61701231 0.53108675 0.18652982 0.05326126 0.52277949\n",
      " 0.66835964 0.52901856 0.22936759] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  800   , loss value =  2.762627666431281\n",
      "\n",
      "W2 =  [[0.42515476 0.20093948 0.44452437 0.97663535 0.6471384  0.31154867\n",
      "  0.87425331 0.70114178 0.41579305]\n",
      " [0.48285467 0.0329838  0.24247705 0.92635637 0.50372657 0.18019825\n",
      "  0.84262521 0.41731607 0.95806543]] \n",
      "\n",
      "b2 =  [0.13937501 0.61996628 0.53135098 0.18719579 0.05541506 0.52298451\n",
      " 0.66187354 0.52831671 0.23247315] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1200   , loss value =  2.754074677207682\n",
      "\n",
      "W2 =  [[0.41111382 0.20160988 0.44022239 0.9969471  0.65185843 0.31000561\n",
      "  0.92147484 0.68038951 0.44004633]\n",
      " [0.47227473 0.02933594 0.23524135 0.9469125  0.50904844 0.17788987\n",
      "  0.88984564 0.3832317  0.96798479]] \n",
      "\n",
      "b2 =  [0.13508043 0.62322032 0.53148506 0.19150753 0.05766743 0.52335596\n",
      " 0.65372027 0.52673569 0.23653297] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1600   , loss value =  2.7437839007560574\n",
      "\n",
      "W2 =  [[0.39719053 0.2039479  0.43556731 1.03448779 0.65596351 0.30807689\n",
      "  0.98110673 0.6620816  0.46651541]\n",
      " [0.46254415 0.02673671 0.22695413 0.98473469 0.51364178 0.17485444\n",
      "  0.94922782 0.35108679 0.9789282 ]] \n",
      "\n",
      "b2 =  [0.13013727 0.62674022 0.53142774 0.19968913 0.05983911 0.52380188\n",
      " 0.64314799 0.52442391 0.24161969] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2000   , loss value =  2.7305240587168007\n",
      "\n",
      "W2 =  [[0.38355434 0.20846866 0.43094901 1.09047762 0.65908075 0.30619426\n",
      "  1.05499907 0.64601024 0.49494432]\n",
      " [0.45407408 0.02574238 0.21799373 1.04089358 0.51709699 0.17160131\n",
      "  1.02252097 0.32031637 0.99082173]] \n",
      "\n",
      "b2 =  [0.12446007 0.63050809 0.53112487 0.21135822 0.06166546 0.52425806\n",
      " 0.62889743 0.52142982 0.24777547] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2400   , loss value =  2.7127337615802216\n",
      "\n",
      "W2 =  [[0.37053892 0.21574953 0.42687817 1.16684054 0.66078087 0.30488602\n",
      "  1.14513878 0.63228911 0.52480718]\n",
      " [0.44752637 0.02697169 0.20885947 1.11716644 0.51895947 0.16875628\n",
      "  1.11160248 0.29064898 1.00345261]] \n",
      "\n",
      "b2 =  [0.11792414 0.63449665 0.53051451 0.22519909 0.06277299 0.52466797\n",
      " 0.60904029 0.51772964 0.25499002] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2800   , loss value =  2.6884335778328055\n",
      "\n",
      "W2 =  [[0.35868586 0.22644375 0.42403572 1.26572625 0.66064713 0.30481323\n",
      "  1.25348529 0.62139711 0.5552421 ]\n",
      " [0.44388725 0.03112745 0.20023567 1.21555476 0.5188193  0.16711379\n",
      "  1.21831537 0.26215754 1.01642528]] \n",
      "\n",
      "b2 =  [0.11033477 0.63862704 0.52950217 0.23847396 0.06265456 0.52495408\n",
      " 0.58087301 0.51323023 0.26317493] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3200   , loss value =  2.6552415107039353\n",
      "\n",
      "W2 =  [[0.34878426 0.24128109 0.42331719 1.38883488 0.65840526 0.30679907\n",
      "  1.38175318 0.61422849 0.58500158]\n",
      " [0.44454325 0.03900606 0.19305361 1.33760815 0.51647447 0.16768442\n",
      "  1.3442548  0.23532272 1.02912912]] \n",
      "\n",
      "b2 =  [0.10135583 0.64269307 0.5279108  0.24664826 0.06064292 0.5249656\n",
      " 0.54101654 0.50773622 0.27213253] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3600   , loss value =  2.610540348562319\n",
      "\n",
      "W2 =  [[0.34189626 0.26105178 0.42586056 1.53670437 0.65412829 0.31184294\n",
      "  1.53116522 0.61212632 0.61244914]\n",
      " [0.45134438 0.05148829 0.18853676 1.48371997 0.51218287 0.17172515\n",
      "  1.49053106 0.21108215 1.040744  ]] \n",
      "\n",
      "b2 =  [0.09036907 0.64623441 0.52538537 0.24366391 0.05587462 0.5243834\n",
      " 0.4859422  0.50085926 0.28150827] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4000   , loss value =  2.5518275789605687\n",
      "\n",
      "W2 =  [[0.33934853 0.2865631  0.43303608 1.70826686 0.64850332 0.32110206\n",
      "  1.70216404 0.61686357 0.63563827]\n",
      " [0.46662384 0.06949485 0.18819841 1.6527073  0.50698309 0.18072624\n",
      "  1.6575048  0.19081904 1.05031814]] \n",
      "\n",
      "b2 =  [0.07623607 0.64835246 0.52123576 0.22337987 0.04722294 0.52256798\n",
      " 0.41310551 0.49184803 0.2906978 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4400   , loss value =  2.4772843120712187\n",
      "\n",
      "W2 =  [[0.3426346  0.31853043 0.44634943 1.90081766 0.64308462 0.3357973\n",
      "  1.8940072  0.63050969 0.65251198]\n",
      " [0.49310449 0.09386139 0.19373094 1.84182152 0.50298862 0.19629972\n",
      "  1.84442539 0.17621328 1.05695517]] \n",
      "\n",
      "b2 =  [0.05696161 0.64749882 0.51423117 0.18201268 0.03317319 0.5183624\n",
      " 0.32254012 0.47935181 0.29866618] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4800   , loss value =  2.3865050050464016\n",
      "\n",
      "W2 =  [[0.35312408 0.35734192 0.46717807 2.11018966 0.64035102 0.3569677\n",
      "  2.10421551 0.65509432 0.66124274]\n",
      " [0.53357104 0.12506885 0.20669794 2.04697588 0.5034417  0.21988711\n",
      "  2.0489394  0.16885739 1.06011973]] \n",
      "\n",
      "b2 =  [0.02933009 0.64133567 0.50242272 0.12027504 0.01164137 0.5099205\n",
      " 0.21803615 0.46120888 0.30368156] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5200   , loss value =  2.2809165368835327\n",
      "\n",
      "W2 =  [[0.37153954 0.4027162  0.49631572 2.33094069 0.64331989 0.38505112\n",
      "  2.32815188 0.69205067 0.6606526 ]\n",
      " [0.59024546 0.16285023 0.22800862 2.26297824 0.51225079 0.25226925\n",
      "  2.26672081 0.16962719 1.05998599]] \n",
      "\n",
      "b2 =  [-0.01129895  0.62683858  0.48314326  0.04338234 -0.02019439  0.49469884\n",
      "  0.10646784  0.43443918  0.30311105] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5600   , loss value =  2.163191477035884\n",
      "\n",
      "W2 =  [[0.39748591 0.45348346 0.53352702 2.55677022 0.65467384 0.41948518\n",
      "  2.55932581 0.74167707 0.65053657]\n",
      " [0.66409281 0.20590765 0.2573911  2.48395662 0.53296374 0.29308619\n",
      "  2.49177696 0.17807246 1.05765055]] \n",
      "\n",
      "b2 =  [-0.07078203  0.60076362  0.45331667 -0.04166385 -0.06592085  0.46974268\n",
      " -0.00513411  0.39560157  0.29356456] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6000   , loss value =  2.03578872530727\n",
      "\n",
      "W2 =  [[0.42964148 0.50778396 0.57749116 2.78140509 0.67585856 0.45868778\n",
      "  2.7906649  0.80304377 0.63172569]\n",
      " [0.75453511 0.25203218 0.29325547 2.70420232 0.56765541 0.3407301\n",
      "  2.71765611 0.19229005 1.0550556 ]] \n",
      "\n",
      "b2 =  [-0.15541947  0.56036379  0.41004039 -0.12963017 -0.12965777  0.43224233\n",
      " -0.11276622  0.34148004  0.2715372 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6400   , loss value =  1.899771096019756\n",
      "\n",
      "W2 =  [[0.46692723 0.56363701 0.62626056 2.99962509 0.70683186 0.5005312\n",
      "  3.01606779 0.87446499 0.60592727]\n",
      " [0.8597215  0.2985942  0.33308681 2.91911052 0.61642864 0.3927246\n",
      "  2.9388981  0.20945279 1.05464283]] \n",
      "\n",
      "b2 =  [-0.27070475  0.50404929  0.35123843 -0.21884689 -0.21549557  0.38016976\n",
      " -0.21648078  0.2698763   0.23433101] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6800   , loss value =  1.7548157792256274\n",
      "\n",
      "W2 =  [[0.51011204 0.61945992 0.67788191 3.20784221 0.74662952 0.542974\n",
      "  3.23130169 0.95409529 0.57550355]\n",
      " [0.97686445 0.34307489 0.37409257 3.12562853 0.6777465  0.44631054\n",
      "  3.15179924 0.22668048 1.05887166]] \n",
      "\n",
      "b2 =  [-0.41986479  0.43180395  0.27621657 -0.31071252 -0.32656991  0.31281972\n",
      " -0.31922837  0.18032921  0.18088963] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************************************************************\n",
      "step =  7200   , loss value =  1.6004234823278436\n",
      "\n",
      "W2 =  [[0.5626451  0.67416921 0.73070276 3.40407658 0.79418348 0.58440593\n",
      "  3.43403034 1.04007497 0.543209  ]\n",
      " [1.10219123 0.38346804 0.41381657 3.32202379 0.74924862 0.49896446\n",
      "  3.35424002 0.24189321 1.06970766]] \n",
      "\n",
      "b2 =  [-0.60261455  0.34539906  0.18608323 -0.40808091 -0.46385939  0.23119817\n",
      " -0.42496738  0.07471124  0.1123348 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  7600   , loss value =  1.4376768536204518\n",
      "\n",
      "W2 =  [[0.62957843 0.72682871 0.78318309 3.58758022 0.84862555 0.62353929\n",
      "  3.62335681 1.13004304 0.51172748]\n",
      " [1.23089203 0.41864052 0.45067212 3.50726881 0.82860876 0.54883015\n",
      "  3.54499726 0.25447978 1.08818684]] \n",
      "\n",
      "b2 =  [-0.81470987  0.24844117  0.08398111 -0.51349897 -0.6250759   0.13820135\n",
      " -0.53691403 -0.04245204  0.03207067] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8000   , loss value =  1.270521789498301\n",
      "\n",
      "W2 =  [[0.71473441 0.77617539 0.83348904 3.75834144 0.9088628  0.65908629\n",
      "  3.79923136 1.2204818  0.48300913]\n",
      " [1.35788757 0.44860025 0.48428635 3.68050119 0.91403899 0.59502461\n",
      "  3.72311749 0.26546261 1.11419747]] \n",
      "\n",
      "b2 =  [-1.04858006  0.14608574 -0.02510066 -0.62770687 -0.80432524  0.03840865\n",
      " -0.65616934 -0.16439988 -0.05470846] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8400   , loss value =  1.105607126777187\n",
      "\n",
      "W2 =  [[0.81816513 0.82055994 0.87945343 3.91658343 0.97310969 0.68971369\n",
      "  3.96188464 1.30681037 0.4578362 ]\n",
      " [1.47926078 0.47431759 0.51530281 3.8408772  1.00406008 0.63755345\n",
      "  3.88771979 0.27672157 1.14652991]] \n",
      "\n",
      "b2 =  [-1.29458544  0.04419494 -0.13518421 -0.74885676 -0.99310296 -0.06268006\n",
      " -0.78108669 -0.28365282 -0.14209324] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8800   , loss value =  0.9505065804723893\n",
      "\n",
      "W2 =  [[0.9358827  0.85849327 0.91916367 4.06242782 1.03913839 0.71446209\n",
      "  4.11146346 1.38460993 0.43602218]\n",
      " [1.59303449 0.49701035 0.54459887 3.98778803 1.0967296  0.67676522\n",
      "  4.03819639 0.28963312 1.18313646]] \n",
      "\n",
      "b2 =  [-1.54248094 -0.05192242 -0.2406661  -0.87291714 -1.18238792 -0.15981911\n",
      " -0.90780196 -0.39405292 -0.22474792] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9200   , loss value =  0.8113404382268559\n",
      "\n",
      "W2 =  [[1.06162315 0.8892961  0.95166726 4.1958891  1.10497599 0.73318792\n",
      "  4.24802352 1.45107895 0.41699114]\n",
      " [1.69870949 0.5174618  0.57256893 4.12112574 1.18930022 0.71281508\n",
      "  4.17447635 0.30431311 1.22158093]] \n",
      "\n",
      "b2 =  [-1.78309451 -0.1385797  -0.33750374 -0.99507506 -1.36473802 -0.24908208\n",
      " -1.03169928 -0.49203797 -0.29889117] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9600   , loss value =  0.6912861080726431\n",
      "\n",
      "W2 =  [[1.18904214 0.9132615  0.9771447  4.31710723 1.16928059 0.74655118\n",
      "  4.37176631 1.50554616 0.40019142]\n",
      " [1.79641573 0.53589605 0.59903695 4.24135231 1.27880979 0.74557639\n",
      "  4.29708823 0.3199452  1.25960079]] \n",
      "\n",
      "b2 =  [-2.00976108 -0.21405691 -0.42363919 -1.11121933 -1.53537109 -0.32832819\n",
      " -1.14888898 -0.57658158 -0.36263636] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  10000   , loss value =  0.5905895226881276\n",
      "\n",
      "W2 =  [[1.31316117 0.9313328  0.99653968 4.4265455  1.23126273 0.75563138\n",
      "  4.48323333 1.54895307 0.38519787]\n",
      " [1.8864611  0.5522609  0.62360454 4.34937514 1.36295009 0.77487094\n",
      "  4.40702227 0.3355154  1.29553687]] \n",
      "\n",
      "b2 =  [-2.21880616 -0.27825818 -0.49869562 -1.21871922 -1.69208867 -0.39702243\n",
      " -1.25694939 -0.64835873 -0.41572229] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XOR Gate 객체 생성\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([0, 1, 1, 0])\n",
    "\n",
    "\n",
    "xor_obj = LogicGate(\"XOR\", xdata, tdata)\n",
    "\n",
    "xor_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.08732785]), 0)\n",
      "(array([0.87132322]), 1)\n",
      "(array([0.85988041]), 1)\n",
      "(array([0.18982677]), 0)\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(xor_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:su] *",
   "language": "python",
   "name": "conda-env-su-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
