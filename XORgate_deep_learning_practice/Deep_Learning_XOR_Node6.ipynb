{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 수치미분 함수\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "        \n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        \n",
    "        self.name = gate_name\n",
    "        \n",
    "        # 입력 데이터, 정답 데이터 초기화\n",
    "        self.__xdata = xdata.reshape(4,2)  # 4개의 입력데이터 x1, x2 에 대하여 batch 처리 행렬\n",
    "        self.__tdata = tdata.reshape(4,1)  # 4개의 입력데이터 x1, x2 에 대한 각각의 계산 값 행렬\n",
    "        \n",
    "        # 2층 hidden layer unit : 6개 가정,  가중치 W2, 바이어스 b2 초기화\n",
    "        self.__W2 = np.random.rand(2,6)  # weight, 2 X 6 matrix\n",
    "        self.__b2 = np.random.rand(6)\n",
    "        \n",
    "        # 3층 output layer unit : 1 개 , 가중치 W3, 바이어스 b3 초기화\n",
    "        self.__W3 = np.random.rand(6,1)\n",
    "        self.__b3 = np.random.rand(1)\n",
    "                        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.__learning_rate = 1e-2\n",
    "    \n",
    "        print(self.name + \" object is created\")\n",
    "            \n",
    "    def feed_forward(self):        # feed forward 를 통하여 손실함수(cross-entropy) 값 계산\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z2 = np.dot(self.__xdata, self.__W2) + self.__b2  # 은닉층의 선형회귀 값\n",
    "        a2 = sigmoid(z2)                                  # 은닉층의 출력\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3            # 출력층의 선형회귀 값\n",
    "        y = a3 = sigmoid(z3)                              # 출력층의 출력\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.__tdata*np.log(y + delta) + (1-self.__tdata)*np.log((1 - y)+delta ) )    \n",
    "    \n",
    "    def loss_val(self):          # 외부 출력을 위한 손실함수(cross-entropy) 값 계산 \n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z2 = np.dot(self.__xdata, self.__W2) + self.__b2  # 은닉층의 선형회귀 값\n",
    "        a2 = sigmoid(z2)                                  # 은닉층의 출력\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3            # 출력층의 선형회귀 값\n",
    "        y = a3 = sigmoid(z3)                              # 출력층의 출력\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.__tdata*np.log(y + delta) + (1-self.__tdata)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    \n",
    "    # 수치미분을 이용하여 손실함수가 최소가 될때 까지 학습하는 함수\n",
    "    def train(self):\n",
    "        \n",
    "        f = lambda x : self.feed_forward()\n",
    "        \n",
    "        print(\"Initial loss value = \", self.loss_val())\n",
    "        \n",
    "        for step in  range(10001):\n",
    "            \n",
    "            self.__W2 -= self.__learning_rate * numerical_derivative(f, self.__W2)\n",
    "    \n",
    "            self.__b2 -= self.__learning_rate * numerical_derivative(f, self.__b2)\n",
    "        \n",
    "            self.__W3 -= self.__learning_rate * numerical_derivative(f, self.__W3)\n",
    "    \n",
    "            self.__b3 -= self.__learning_rate * numerical_derivative(f, self.__b3)\n",
    "    \n",
    "            if (step % 400 == 0):\n",
    "                print(\"\\n*****************************************************************************\")\n",
    "                print(\"step = \", step, \"  , loss value = \", self.loss_val())\n",
    "                print(\"\\nW2 = \" , self.__W2, \"\\n\")\n",
    "                print(\"b2 = \" , self.__b2, \"\\n\")\n",
    "                \n",
    "    \n",
    "    # query, 즉 미래 값 예측 함수\n",
    "    def predict(self, xdata):\n",
    "        \n",
    "        z2 = np.dot(xdata, self.__W2) + self.__b2         # 은닉층의 선형회귀 값\n",
    "        a2 = sigmoid(z2)                                  # 은닉층의 출력\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3            # 출력층의 선형회귀 값\n",
    "        y = a3 = sigmoid(z3)                              # 출력층의 출력\n",
    "    \n",
    "        if y > 0.5:\n",
    "            result = 1  # True\n",
    "        else:\n",
    "            result = 0  # False\n",
    "    \n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND object is created\n",
      "Initial loss value =  7.857415836115302\n",
      "\n",
      "*****************************************************************************\n",
      "step =  0   , loss value =  7.560540411791716\n",
      "\n",
      "W2 =  [[0.27131878 0.04431251 0.92402048 0.66427315 0.49256973 0.91603111]\n",
      " [0.60041714 0.4946732  0.62878787 0.44852881 0.60840316 0.95246285]] \n",
      "\n",
      "b2 =  [0.63829351 0.82428735 0.13108985 0.16549603 0.63902744 0.39416276] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  400   , loss value =  2.1580494605277254\n",
      "\n",
      "W2 =  [[0.23254104 0.01078072 0.97669124 0.66706558 0.44648655 0.90650917]\n",
      " [0.55622934 0.46072039 0.67031727 0.44972529 0.55560916 0.94430708]] \n",
      "\n",
      "b2 =  [ 0.64984914  0.78828139 -0.14577841  0.09485076  0.72906417  0.31565178] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  800   , loss value =  2.007731224751578\n",
      "\n",
      "W2 =  [[ 0.192256   -0.03975745  1.11328742  0.72227519  0.39200984  0.92163477]\n",
      " [ 0.50584942  0.39709526  0.80436554  0.50563813  0.49173083  0.96513742]] \n",
      "\n",
      "b2 =  [ 0.69182438  0.81974272 -0.41915151  0.03453025  0.81279487  0.21258283] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1200   , loss value =  1.792298399456789\n",
      "\n",
      "W2 =  [[ 0.145998   -0.1239623   1.2773493   0.80428296  0.33534832  0.94335105]\n",
      " [ 0.44533678  0.2884636   0.98753575  0.59359691  0.42209392  1.00260908]] \n",
      "\n",
      "b2 =  [ 0.73570102  0.86077435 -0.81430512 -0.0759843   0.89071843  0.03383734] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1600   , loss value =  1.5091207912140923\n",
      "\n",
      "W2 =  [[ 0.09268301 -0.24939375  1.44947574  0.8942424   0.2751018   0.966505  ]\n",
      " [ 0.37251908  0.12524178  1.22286488  0.69915897  0.34481042  1.05732623]] \n",
      "\n",
      "b2 =  [ 0.78003548  0.89909808 -1.29424752 -0.23505084  0.96248629 -0.20665383] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2000   , loss value =  1.191822114712405\n",
      "\n",
      "W2 =  [[ 0.03289156 -0.4213113   1.62337299  0.97745367  0.21137559  0.99134903]\n",
      " [ 0.29038131 -0.0926698   1.49463194  0.80557416  0.2629872   1.12660641]] \n",
      "\n",
      "b2 =  [ 0.82078039  0.92353127 -1.79160715 -0.42757132  1.02431143 -0.47988861] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2400   , loss value =  0.8947776134383136\n",
      "\n",
      "W2 =  [[-0.03146193 -0.62356837  1.80302378  1.04955119  0.14556611  1.02418237]\n",
      " [ 0.2056658  -0.33676812  1.76051482  0.89941776  0.18261382  1.20184963]] \n",
      "\n",
      "b2 =  [ 0.85484276  0.94294818 -2.24697636 -0.62872324  1.07380434 -0.74903047] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2800   , loss value =  0.6602597084129922\n",
      "\n",
      "W2 =  [[-0.09689375 -0.81312869  1.98005408  1.11172263  0.08052239  1.06720413]\n",
      " [ 0.12438708 -0.55595669  1.98854612  0.97668812  0.10798069  1.27424933]] \n",
      "\n",
      "b2 =  [ 0.88154667  0.98384965 -2.63094592 -0.81589902  1.11137182 -0.9867683 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3200   , loss value =  0.4936355454294742\n",
      "\n",
      "W2 =  [[-0.16014187 -0.96316543  2.14127123  1.16585087  0.01865029  1.11627531]\n",
      " [ 0.04935535 -0.72485787  2.17429501  1.0405407   0.04012848  1.34010973]] \n",
      "\n",
      "b2 =  [ 0.90168401  1.05330249 -2.9417445  -0.97798234  1.13886535 -1.1843854 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3600   , loss value =  0.37858922228182085\n",
      "\n",
      "W2 =  [[-0.21927562 -1.07583537  2.28062554  1.21318587 -0.03890126  1.1662402 ]\n",
      " [-0.01873249 -0.85012182  2.32475248  1.09471872 -0.0213674   1.39878526]] \n",
      "\n",
      "b2 =  [ 0.91670929  1.1384304  -3.19135876 -1.11415798  1.15858626 -1.34557623] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4000   , loss value =  0.29834815908771384\n",
      "\n",
      "W2 =  [[-0.27348748 -1.16154719  2.39851849  1.25460708 -0.09184026  1.21383313]\n",
      " [-0.08000005 -0.94522245  2.44771433  1.14154671 -0.07714839  1.45054798]] \n",
      "\n",
      "b2 =  [ 0.92814563  1.22679024 -3.39366318 -1.22801364  1.17267974 -1.47760425] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4400   , loss value =  0.24109470427541424\n",
      "\n",
      "W2 =  [[-0.32266907 -1.22887449  2.49798509  1.29092909 -0.14031791  1.25766363]\n",
      " [-0.13491152 -1.02023377  2.54952864  1.18245946 -0.12782898  1.49604479]] \n",
      "\n",
      "b2 =  [ 0.93722206  1.31173882 -3.56009048 -1.32385914  1.18283798 -1.58718656] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4800   , loss value =  0.19918367666891135\n",
      "\n",
      "W2 =  [[-0.36707926 -1.28351015  2.58243444  1.32292505 -0.18467425  1.29743521]\n",
      " [-0.18407956 -1.08152158  2.63502895  1.21848465 -0.17397875  1.53607582]] \n",
      "\n",
      "b2 =  [ 0.94480649  1.39062758 -3.6992137  -1.40545184  1.190289   -1.67956268] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5200   , loss value =  0.16772844356632435\n",
      "\n",
      "W2 =  [[-0.40713705 -1.3291039   2.65484171  1.35128524 -0.22530515  1.33335237]\n",
      " [-0.22815542 -1.13304635  2.70782563  1.25043207 -0.21611649  1.57144274]] \n",
      "\n",
      "b2 =  [ 0.95147002  1.46281465 -3.81730286 -1.47576443  1.19589195 -1.75861803] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5600   , loss value =  0.14357059129267138\n",
      "\n",
      "W2 =  [[-0.44330794 -1.3680323   2.71759408  1.37659712 -0.26260135  1.36580237]\n",
      " [-0.26776615 -1.17734409  2.77060846  1.27896041 -0.25470572  1.60286961]] \n",
      "\n",
      "b2 =  [ 0.95757309  1.52853522 -3.91894125 -1.53707449  1.20023948 -1.82720667] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6000   , loss value =  0.1246284593780542\n",
      "\n",
      "W2 =  [[-0.47604668 -1.40189061  2.77255166  1.39934742 -0.29692383  1.39520793]\n",
      " [-0.30348388 -1.216105    2.82539253  1.30460858 -0.29015463  1.63097636]] \n",
      "\n",
      "b2 =  [ 0.96333663  1.58835432 -4.00751074 -1.59111587  1.20373879 -1.8874392 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6400   , loss value =  0.10949912677239726\n",
      "\n",
      "W2 =  [[-0.50577151 -1.43178552  2.821154    1.41993447 -0.32859617  1.42196644]\n",
      " [-0.33581468 -1.25050111  2.87370221  1.32781737 -0.32281975  1.65627975]] \n",
      "\n",
      "b2 =  [ 0.9688926   1.64291983 -4.08554041 -1.63921479  1.20666975 -1.94089698] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6800   , loss value =  0.09721552876599512\n",
      "\n",
      "W2 =  [[-0.5328549  -1.45850913  2.86451879  1.43868302 -0.35790433  1.44642938]\n",
      " [-0.36519821 -1.28137453  2.91670431  1.34894748 -0.35301115  1.67920526]] \n",
      "\n",
      "b2 =  [ 0.97431759  1.69285814 -4.15494975 -1.68239559  1.20922498 -1.98878298] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  7200   , loss value =  0.08709643386274601\n",
      "\n",
      "W2 =  [[-0.5576227  -1.48264448  2.90352056  1.45585818 -0.3850994   1.46889899]\n",
      " [-0.39201252 -1.30934915  2.95530312  1.36829475 -0.38099828  1.7001019 ]] \n",
      "\n",
      "b2 =  [ 0.97965429  1.73873521 -4.21721742 -1.72145869  1.21153714 -2.03202657] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  7600   , loss value =  0.07865211500932782\n",
      "\n",
      "W2 =  [[-0.58035712 -1.50463148  2.93885033  1.47167724 -0.4104013   1.48963195]\n",
      " [-0.41658102 -1.33489932  2.99020826  1.38610275 -0.40701537  1.71925623]] \n",
      "\n",
      "b2 =  [ 0.98492502  1.78104673 -4.27349884 -1.75703718  1.21369749 -2.07135647] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8000   , loss value =  0.07152384412553156\n",
      "\n",
      "W2 =  [[-0.60130138 -1.52480925  2.97105977  1.48631933 -0.43400265  1.50884528]\n",
      " [-0.43917977 -1.35839377  3.02198336  1.40257308 -0.4312664   1.73690433]] \n",
      "\n",
      "b2 =  [ 0.99014013  1.8202206  -4.32470903 -1.78963785  1.2157686  -2.10735204] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8400   , loss value =  0.06544428351860264\n",
      "\n",
      "W2 =  [[-0.62066471 -1.5434442   3.00059391  1.49993301 -0.4560723   1.52672238]\n",
      " [-0.46004449 -1.38012455  3.05108123  1.41787354 -0.45392941  1.75324177]] \n",
      "\n",
      "b2 =  [ 0.99530317  1.85662389 -4.37158175 -1.81967101  1.21779303 -2.14047983] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************************************************************\n",
      "step =  8800   , loss value =  0.06021103605621456\n",
      "\n",
      "W2 =  [[-0.63862705 -1.56074909  3.02781538  1.5126424  -0.47675855  1.54341864]\n",
      " [-0.47937669 -1.40032676  3.07786956  1.43214466 -0.47516021  1.76843146]] \n",
      "\n",
      "b2 =  [ 1.00041393  1.89057108 -4.4147122  -1.84747239  1.21979934 -2.17111993] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9200   , loss value =  0.055668643992607014\n",
      "\n",
      "W2 =  [[-0.65534343 -1.57689631  3.05302247  1.52455182 -0.49619192  1.55906615]\n",
      " [-0.49734911 -1.41919233  3.10264997  1.44550488 -0.49509554  1.78260997]] \n",
      "\n",
      "b2 =  [ 1.00547042  1.92233182 -4.45458834 -1.87331947  1.22180632 -2.19958538] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9600   , loss value =  0.051696116679843925\n",
      "\n",
      "W2 =  [[-0.67094765 -1.59202735  3.07646277  1.53574958 -0.51448757  1.57377771]\n",
      " [-0.51411024 -1.43687985  3.1256722   1.45805462 -0.51385572  1.79589254]] \n",
      "\n",
      "b2 =  [ 1.0104699   1.95213797 -4.49161409 -1.89744368  1.22382589 -2.22613648] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  10000   , loss value =  0.04819814324461722\n",
      "\n",
      "W2 =  [[-0.68555556 -1.60625964  3.09834352  1.54631093 -0.53174736  1.58765012]\n",
      " [-0.52978818 -1.45352183  3.14714481  1.46987957 -0.53154699  1.80837702]] \n",
      "\n",
      "b2 =  [ 1.01540951  1.98018957 -4.52612684 -1.92003968  1.2258652  -2.25099165] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AND Gate 객체 생성 및 training\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([0, 0, 0, 1])\n",
    "\n",
    "and_obj = LogicGate(\"AND\", xdata, tdata)\n",
    "\n",
    "and_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.00021671]), 0)\n",
      "(array([0.01270217]), 0)\n",
      "(array([0.01298618]), 0)\n",
      "(array([0.97811597]), 1)\n"
     ]
    }
   ],
   "source": [
    "# AND Gate prediction\n",
    "\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(and_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR object is created\n",
      "Initial loss value =  2.7524555085641276\n",
      "\n",
      "*****************************************************************************\n",
      "step =  0   , loss value =  2.7348391986675304\n",
      "\n",
      "W2 =  [[0.90551382 0.07057456 0.26304294 0.95993983 0.99968297 0.46228942]\n",
      " [0.17499208 0.70608473 0.2069516  0.51666071 0.03815778 0.49789214]] \n",
      "\n",
      "b2 =  [0.55017454 0.70485939 0.60068648 0.01724031 0.55682268 0.01332848] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  400   , loss value =  2.0178144973705043\n",
      "\n",
      "W2 =  [[1.00889639 0.12012986 0.30001267 0.97259969 1.00473241 0.68038624]\n",
      " [0.30548604 0.74842845 0.24520009 0.53108662 0.04501442 0.71990472]] \n",
      "\n",
      "b2 =  [ 0.38373587  0.64041409  0.55554984  0.0047772   0.54007201 -0.16940006] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  800   , loss value =  1.8045495850506694\n",
      "\n",
      "W2 =  [[1.14040755 0.15890271 0.30383875 1.05945169 1.01232469 0.97287678]\n",
      " [0.47617026 0.78196958 0.24916791 0.63231075 0.05560349 1.02416432]] \n",
      "\n",
      "b2 =  [ 0.21189089  0.60844421  0.55351984 -0.07807336  0.53129959 -0.37024233] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1200   , loss value =  1.4970221204631171\n",
      "\n",
      "W2 =  [[1.29312621 0.18227549 0.27279948 1.20248547 1.01633315 1.31445299]\n",
      " [0.67992637 0.80242394 0.2154421  0.80435943 0.06140569 1.38826207]] \n",
      "\n",
      "b2 =  [-0.01401657  0.58677745  0.57350574 -0.23040164  0.52629404 -0.64709942] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1600   , loss value =  1.137246067802797\n",
      "\n",
      "W2 =  [[1.46027312 0.18866474 0.21091743 1.37522699 1.01157485 1.67615563]\n",
      " [0.90654954 0.80804538 0.14674323 1.01756274 0.05406959 1.7801314 ]] \n",
      "\n",
      "b2 =  [-0.26573692  0.58039835  0.61426038 -0.42210195  0.53287733 -0.92730113] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2000   , loss value =  0.8138963080503216\n",
      "\n",
      "W2 =  [[1.62684235 0.18177247 0.13165529 1.55081896 0.99931191 2.01600605]\n",
      " [1.1323293  0.80201647 0.05743781 1.23666773 0.03450281 2.14768925]] \n",
      "\n",
      "b2 =  [-0.49591615  0.58770865  0.66497483 -0.60730168  0.55063296 -1.1484721 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2400   , loss value =  0.576175911505214\n",
      "\n",
      "W2 =  [[ 1.77814747  0.16778941  0.04966202  1.71001995  0.98362188  2.30485023]\n",
      " [ 1.33463151  0.78993637 -0.03534436  1.43437454  0.00886995  2.45439413]] \n",
      "\n",
      "b2 =  [-0.67768116  0.60275979  0.71403751 -0.75856856  0.57407145 -1.30790473] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2800   , loss value =  0.4176578266076523\n",
      "\n",
      "W2 =  [[ 1.90788998  0.15145347 -0.02669832  1.84583357  0.96760319  2.53759931]\n",
      " [ 1.50478655  0.77606107 -0.1214261   1.60074293 -0.01759263  2.69562957]] \n",
      "\n",
      "b2 =  [-0.81280446  0.62039461  0.75590521 -0.87402333  0.59840658 -1.42439199] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3200   , loss value =  0.313904010597413\n",
      "\n",
      "W2 =  [[ 2.01681101  0.13517365 -0.0948466   1.95936291  0.95264763  2.72288817]\n",
      " [ 1.64487162  0.76247401 -0.19765243  1.73756604 -0.04239151  2.88341451]] \n",
      "\n",
      "b2 =  [-0.91326803  0.63789601  0.78992932 -0.96175154  0.62130295 -1.51281067] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3600   , loss value =  0.2445787644581671\n",
      "\n",
      "W2 =  [[ 2.10829098  0.11987808 -0.1549636   2.05441408  0.93913693  2.87183843]\n",
      " [ 1.76046533  0.74991475 -0.26428361  1.85032909 -0.06479987  3.03160593]] \n",
      "\n",
      "b2 =  [-0.98988791  0.65422014  0.81731006 -1.02986036  0.64204264 -1.58234133] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4000   , loss value =  0.19665875703194727\n",
      "\n",
      "W2 =  [[ 2.1858746   0.10581283 -0.20808614  2.13484162  0.92704056  2.99370334]\n",
      " [ 1.8570046   0.73853209 -0.32262491  1.9444031  -0.08483795  3.15107726]] \n",
      "\n",
      "b2 =  [-1.05016093  0.66910546  0.8395     -1.08421718  0.66060999 -1.63865019] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4400   , loss value =  0.1623409439284765\n",
      "\n",
      "W2 =  [[ 2.25250728  0.09295717 -0.2553435   2.20379784  0.91620007  3.09530095]\n",
      " [ 1.93882783  0.72826005 -0.37407626  2.02406769 -0.1027645   3.2495203 ]] \n",
      "\n",
      "b2 =  [-1.09896552  0.68259365  0.8577203  -1.12874955  0.67722358 -1.6853707 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4800   , loss value =  0.13695063530303508\n",
      "\n",
      "W2 =  [[ 2.31046502  0.08120133 -0.2977258   2.26369647  0.90643776  3.18149619]\n",
      " [ 2.00919206  0.71897117 -0.41985102  2.09252887 -0.11887872  3.33225895]] \n",
      "\n",
      "b2 =  [-1.13947872  0.69482393  0.87290008 -1.16607122  0.69214905 -1.72492231] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5200   , loss value =  0.11762014577329777\n",
      "\n",
      "W2 =  [[ 2.36147149  0.07041641 -0.3360444   2.31635472  0.89759211  3.25576321]\n",
      " [ 2.07050877  0.71053291 -0.46093346  2.15215551 -0.13345458  3.40300642]] \n",
      "\n",
      "b2 =  [-1.17381643  0.70595326  0.88572625 -1.19795388  0.7056346  -1.75897079] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5600   , loss value =  0.1025348299478971\n",
      "\n",
      "W2 =  [[ 2.40683279  0.06047992 -0.37095006  2.3631439   0.88952609  3.32061634]\n",
      " [ 2.12457156  0.70282594 -0.49810576  2.20470643 -0.1467248   3.46439998]] \n",
      "\n",
      "b2 =  [-1.20342861  0.71612804  0.89670549 -1.22562969  0.71789362 -1.78869741] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6000   , loss value =  0.09050924019108814\n",
      "\n",
      "W2 =  [[ 2.44754762  0.0512836  -0.40296304  2.40510945  0.88212634  3.37790781]\n",
      " [ 2.17273051  0.69574833 -0.53198802  2.25150353 -0.15888175  3.5183528 ]] \n",
      "\n",
      "b2 =  [-1.22933778  0.72547605  0.90621469 -1.24997861  0.72910399 -1.81496205] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6400   , loss value =  0.08074527983551856\n",
      "\n",
      "W2 =  [[ 2.48438913  0.04273458 -0.43250116  2.44305882  0.87529976  3.42902758]\n",
      " [ 2.21601668  0.68921466 -0.5630744   2.2935551  -0.17008316  3.56628235]] \n",
      "\n",
      "b2 =  [-1.25228459  0.73410587  0.91453764 -1.27164498  0.73941244 -1.83840541] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6800   , loss value =  0.07269062246402012\n",
      "\n",
      "W2 =  [[ 2.51796387  0.03475404 -0.45990268  2.47762429  0.8689698   3.47503757]\n",
      " [ 2.25522939  0.68315383 -0.59176214  2.33164198 -0.18045843  3.60925999]] \n",
      "\n",
      "b2 =  [-1.27281868  0.74210887  0.92189104 -1.29111153  0.74893996 -1.85951483] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  7200   , loss value =  0.06595341240203356\n",
      "\n",
      "W2 =  [[ 2.54875397  0.02727531 -0.48544392  2.50930774  0.86307322  3.51676271]\n",
      " [ 2.29099734  0.67750657 -0.61837364  2.36637778 -0.19011418  3.64811033]] \n",
      "\n",
      "b2 =  [-1.2913568   0.74956183  0.92844262 -1.3087473   0.75778662 -1.87866782] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  7600   , loss value =  0.06024937966832806\n",
      "\n",
      "W2 =  [[ 2.57714748  0.02024186 -0.50935281  2.53851258  0.85755747  3.55485372]\n",
      " [ 2.3238218   0.67222331 -0.64317318  2.39825135 -0.19913886  3.68347867]] \n",
      "\n",
      "b2 =  [-1.30822105  0.75652938  0.93432398 -1.32483966  0.76603567 -1.89616167] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8000   , loss value =  0.05536814613599929\n",
      "\n",
      "W2 =  [[ 2.60346039  0.01360563 -0.53181906  2.56556698  0.85237855  3.58983111]\n",
      " [ 2.35410751  0.66726234 -0.66637954  2.42765714 -0.20760635  3.7158776 ]] \n",
      "\n",
      "b2 =  [-1.32366468  0.76306619  0.9396396  -1.339616    0.77375686 -1.91223391] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8400   , loss value =  0.05115120791127721\n",
      "\n",
      "W2 =  [[ 2.62795278  0.00732554 -0.55300199  2.59074082  0.84749933  3.62211652]\n",
      " [ 2.38218503  0.66258839 -0.68817545  2.45491715 -0.21557885  3.74571979]] \n",
      "\n",
      "b2 =  [-1.33788982  0.76921872  0.94447342 -1.35325887  0.78100898 -1.92707682] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8800   , loss value =  0.04747720834246265\n",
      "\n",
      "W2 =  [[ 2.65084089e+00  1.36629363e-03 -5.73036536e-01  2.61425828e+00\n",
      "   8.42888296e-01  3.65205541e+00]\n",
      " [ 2.40832726e+00  6.58171398e-01 -7.08714889e-01  2.48029703e+00\n",
      "  -2.23109061e-01  3.77334155e+00]] \n",
      "\n",
      "b2 =  [-1.35106     0.77502667  0.94889361 -1.36591675  0.78784199 -1.94084792] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************************************************************\n",
      "step =  9200   , loss value =  0.04425187498919364\n",
      "\n",
      "W2 =  [[ 2.6723061  -0.00430259 -0.5920378   2.6363073   0.83851847  3.67993386]\n",
      " [ 2.43276164  0.65398563 -0.72812864  2.50401813 -0.23024199  3.79901996]] \n",
      "\n",
      "b2 =  [-1.36330915  0.78052419  0.95295604 -1.37771179  0.79429857 -1.95367758] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9600   , loss value =  0.04140100796897924\n",
      "\n",
      "W2 =  [[ 2.69250186 -0.0097076  -0.61010475  2.65704677  0.83436666  3.70599096]\n",
      " [ 2.45567945  0.65000888 -0.74652859  2.52626651 -0.23701632  3.82298563]] \n",
      "\n",
      "b2 =  [-1.37474814  0.78574078  0.95670694 -1.38874556  0.80041545 -1.96567478] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  10000   , loss value =  0.03886550643333756\n",
      "\n",
      "W2 =  [[ 2.71155898 -0.01487184 -0.62732296  2.67661209  0.83041274  3.73042831]\n",
      " [ 2.47724284  0.6462219  -0.76401117  2.54719984 -0.24346549  3.84543221]] \n",
      "\n",
      "b2 =  [-1.38546968  0.79070211  0.96018489 -1.39910333  0.80622441 -1.97693142] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OR Gate 객체 생성 및 training\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([0, 1, 1, 1])\n",
    "\n",
    "or_obj = LogicGate(\"OR\", xdata, tdata)\n",
    "\n",
    "or_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.02214897]), 0)\n",
      "(array([0.99212691]), 1)\n",
      "(array([0.99210227]), 1)\n",
      "(array([0.99936556]), 1)\n"
     ]
    }
   ],
   "source": [
    "# OR Gate prediction\n",
    "\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(or_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND object is created\n",
      "Initial loss value =  3.077560274526884\n",
      "\n",
      "*****************************************************************************\n",
      "step =  0   , loss value =  3.048820861899971\n",
      "\n",
      "W2 =  [[0.44977019 0.28420476 0.10718483 0.87120376 0.98653187 0.17172484]\n",
      " [0.32132013 0.35168131 0.99190974 0.08737872 0.5288921  0.82498159]] \n",
      "\n",
      "b2 =  [0.32130911 0.77692842 0.68869149 0.78345068 0.78156766 0.64534591] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  400   , loss value =  2.251911879301405\n",
      "\n",
      "W2 =  [[0.539277   0.27709852 0.15012547 0.80152438 0.90315809 0.10947303]\n",
      " [0.40417845 0.34459724 1.05770305 0.03700965 0.47351467 0.7509013 ]] \n",
      "\n",
      "b2 =  [0.27191197 0.77187355 0.61569674 0.81678116 0.91675163 0.67913214] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  800   , loss value =  2.1793592644434057\n",
      "\n",
      "W2 =  [[0.66456781 0.27347855 0.204648   0.75518527 0.84876845 0.07434103]\n",
      " [0.51621152 0.34108753 1.14972047 0.00731806 0.44362493 0.70711587]] \n",
      "\n",
      "b2 =  [0.15958289 0.77432691 0.48127772 0.85533667 1.04470218 0.71536181] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1200   , loss value =  2.0764689712820905\n",
      "\n",
      "W2 =  [[ 0.82596582  0.26255893  0.27250528  0.71131946  0.80042972  0.04441354]\n",
      " [ 0.65250548  0.33069763  1.26916048 -0.020352    0.4180159   0.67066478]] \n",
      "\n",
      "b2 =  [-0.03371125  0.78159678  0.28151198  0.88850616  1.15229342  0.7429579 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1600   , loss value =  1.9179586758934941\n",
      "\n",
      "W2 =  [[ 1.02386782  0.24205333  0.35575081  0.66434199  0.75430532  0.01449211]\n",
      " [ 0.80217287  0.31181699  1.41619947 -0.04878297  0.3956449   0.63528517]] \n",
      "\n",
      "b2 =  [-3.38854668e-01  7.94644814e-01  9.01764378e-04  9.20693480e-01\n",
      "  1.24931131e+00  7.67736121e-01] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2000   , loss value =  1.6866536346117142\n",
      "\n",
      "W2 =  [[ 1.260319    0.2102027   0.46022975  0.61081282  0.70915958 -0.01940337]\n",
      " [ 0.95203614  0.28383308  1.58265795 -0.07904829  0.37700743  0.5966756 ]] \n",
      "\n",
      "b2 =  [-0.75837549  0.81323444 -0.35634983  0.95329431  1.33870262  0.79245506] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2400   , loss value =  1.3999246854113798\n",
      "\n",
      "W2 =  [[ 1.53222335  0.16784021  0.59452898  0.55106559  0.66641413 -0.05843694]\n",
      " [ 1.1010438   0.24827955  1.74797191 -0.11050746  0.36279919  0.55368093]] \n",
      "\n",
      "b2 =  [-1.24439451  0.83500033 -0.75737546  0.98485991  1.41864763  0.81688058] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2800   , loss value =  1.1059582246336244\n",
      "\n",
      "W2 =  [[ 1.81361058  0.11857941  0.76107263  0.48838214  0.62858609 -0.10082427]\n",
      " [ 1.26661083  0.20759508  1.89062229 -0.14265247  0.35214669  0.50738553]] \n",
      "\n",
      "b2 =  [-1.72751796  0.85686033 -1.16182226  1.01319965  1.48695137  0.83955565] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3200   , loss value =  0.8472707595704908\n",
      "\n",
      "W2 =  [[ 2.06589137  0.0668851   0.95009444  0.426493    0.59713043 -0.14364481]\n",
      " [ 1.45601711  0.16396764  2.00443427 -0.17556085  0.34336734  0.45968724]] \n",
      "\n",
      "b2 =  [-2.1636632   0.87663931 -1.53965713  1.03703229  1.54336552  0.85940575] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3600   , loss value =  0.6427213557397784\n",
      "\n",
      "W2 =  [[ 2.27026633  0.01632123  1.1436313   0.36813735  0.57190046 -0.18455837]\n",
      " [ 1.65404492  0.11957043  2.09619052 -0.20883011  0.33549503  0.41273147]] \n",
      "\n",
      "b2 =  [-2.5375705   0.89331027 -1.87180353  1.05609797  1.58906131  0.87598828] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4000   , loss value =  0.4915185962484546\n",
      "\n",
      "W2 =  [[ 2.43028477 -0.03105357  1.3251626   0.31471678  0.55187276 -0.22234306]\n",
      " [ 1.84174977  0.07637275  2.17382604 -0.24151218  0.32834556  0.36828084]] \n",
      "\n",
      "b2 =  [-2.84908448  0.90680491 -2.15188135  1.07091186  1.62588124  0.88944807] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4400   , loss value =  0.38315574291149934\n",
      "\n",
      "W2 =  [[ 2.55669744 -0.07447065  1.48614732  0.26651028  0.53586082 -0.25668283]\n",
      " [ 2.00887648  0.03563177  2.24176536 -0.27276966  0.32195778  0.32725247]] \n",
      "\n",
      "b2 =  [-3.10567371  0.91759522 -2.38391418  1.0823365   1.65576412  0.90028426] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4800   , loss value =  0.3057143725614341\n",
      "\n",
      "W2 =  [[ 2.65895198e+00 -1.13926802e-01  1.62512955e+00  2.23160364e-01\n",
      "   5.22853575e-01 -2.87754228e-01]\n",
      " [ 2.15334683e+00 -2.14829528e-03  2.30209090e+00 -3.02176040e-01\n",
      "   3.16319684e-01  2.89826716e-01]] \n",
      "\n",
      "b2 =  [-3.317451    0.92627984 -2.57619855  1.09120853  1.68037061  0.90906345] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5200   , loss value =  0.24961116472032607\n",
      "\n",
      "W2 =  [[ 2.74370062 -0.14975184  1.74417877  0.18407821  0.51208789 -0.31591807]\n",
      " [ 2.27713329 -0.0369411   2.35600626 -0.32963325  0.31135658  0.25578497]] \n",
      "\n",
      "b2 =  [-3.49397138  0.93338448 -2.73708238  1.09819495  1.70097836  0.91627367] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5600   , loss value =  0.2081089426597158\n",
      "\n",
      "W2 =  [[ 2.8154314  -0.18236911  1.84638675  0.14865887  0.50301346 -0.34156201]\n",
      " [ 2.38340501 -0.06894217  2.40442065 -0.35521715  0.30697242  0.22476393]] \n",
      "\n",
      "b2 =  [-3.64303468  0.93931627 -2.87346343  1.10378918  1.71852663  0.9222932 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6000   , loss value =  0.17670104806475745\n",
      "\n",
      "W2 =  [[ 2.8772119  -0.21219112  1.93474734  0.11636385  0.49523729 -0.36503884]\n",
      " [ 2.47526752 -0.09842126  2.44810205 -0.37907364  0.30307512  0.19638351]] \n",
      "\n",
      "b2 =  [-3.7706289   0.94437638 -2.99064759  1.10834788  1.73369799  0.92740419] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6400   , loss value =  0.1524026731480591\n",
      "\n",
      "W2 =  [[ 2.93119711 -0.23958372  2.01180348  0.08673998  0.48847657 -0.38665002]\n",
      " [ 2.55536613 -0.12565378  2.48770977 -0.40136581  0.29958547  0.17029703]] \n",
      "\n",
      "b2 =  [-3.88125526  0.9487845  -3.09262475  1.11212866  1.74699108  0.93181517] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6800   , loss value =  0.13321968590557237\n",
      "\n",
      "W2 =  [[ 2.97894465 -0.26485943  2.07960918  0.0594138   0.48252478 -0.40664693]\n",
      " [ 2.62583866 -0.1508938   2.52380528 -0.42225089  0.2964382   0.14620482]] \n",
      "\n",
      "b2 =  [-3.97829201  0.9527009  -3.18239114  1.11531907  1.75877488  0.93568072] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  7200   , loss value =  0.11779711139980684\n",
      "\n",
      "W2 =  [[ 3.02160968 -0.28828159  2.13979367  0.03407912  0.47722837 -0.42523773]\n",
      " [ 2.68838061 -0.17436604  2.55686277 -0.44187172  0.29358035  0.12385345]] \n",
      "\n",
      "b2 =  [-4.06429394  0.95624316 -3.26221516  1.11805728  1.76932677  0.93911645] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  7600   , loss value =  0.10519571484860095\n",
      "\n",
      "W2 =  [[ 3.06006856 -0.31007154  2.19364465  0.01048419  0.47247111 -0.44259503]\n",
      " [ 2.74433179 -0.1962657   2.58728092 -0.46035476  0.29096909  0.10303003]] \n",
      "\n",
      "b2 =  [-4.14121578  0.95949821 -3.33383509  1.12044625  1.77885867  0.94220974] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8000   , loss value =  0.09475096840262337\n",
      "\n",
      "W2 =  [[ 3.0949993  -0.33041576  2.2421835  -0.01157927  0.46816349 -0.45886269]\n",
      " [ 2.79475475 -0.21676129  2.61539469 -0.47781072  0.28856959  0.08355568]] \n",
      "\n",
      "b2 =  [-4.21057289  0.96253088 -3.39860097  1.12256367  1.78753513  0.9450274 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8400   , loss value =  0.08598329426678514\n",
      "\n",
      "W2 =  [[ 3.12693559 -0.34947219  2.28622598 -0.03228497  0.46423544 -0.47416143]\n",
      " [ 2.84049804 -0.23599815  2.641486   -0.49433626  0.28635339  0.06527953]] \n",
      "\n",
      "b2 =  [-4.27355574  0.96538988 -3.45757561  1.12446874  1.79548583  0.94762104] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************************************************************\n",
      "step =  8800   , loss value =  0.07854008303327778\n",
      "\n",
      "W2 =  [[ 3.15630398 -0.36737541  2.32642917 -0.05177899  0.4606313  -0.48859334]\n",
      " [ 2.88224514 -0.2541019   2.66579296 -0.51001577  0.28429702  0.04807362]] \n",
      "\n",
      "b2 =  [-4.33111168  0.96811211 -3.51160658  1.12620704  1.80281436  0.95003096] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9200   , loss value =  0.07215756897624007\n",
      "\n",
      "W2 =  [[ 3.18344993 -0.38424085  2.36332708 -0.07018523  0.45730623 -0.50224542]\n",
      " [ 2.92055156 -0.27118153  2.68851757 -0.52492318  0.28238099  0.03182879]] \n",
      "\n",
      "b2 =  [-4.38400379  0.97072567 -3.5613781   1.12781394  1.80960457  0.9522889 ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9600   , loss value =  0.06663529325118461\n",
      "\n",
      "W2 =  [[ 3.20865665 -0.40016815  2.39735765 -0.08760962  0.45422371 -0.51519234]\n",
      " [ 2.95587289 -0.28733199  2.70983204 -0.53912344  0.28058897  0.01645127]] \n",
      "\n",
      "b2 =  [-4.43285371  0.97325213 -3.6074488   1.12931708  1.8159251   0.95442013] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  10000   , loss value =  0.06181868254377587\n",
      "\n",
      "W2 =  [[ 3.23215881e+00 -4.15243850e-01  2.42888316e+00 -1.04143408e-01\n",
      "   4.51353616e-01 -5.27498677e-01]\n",
      " [ 2.98858607e+00 -3.02636402e-01  2.72988393e+00 -5.52673912e-01\n",
      "   2.78907159e-01  1.86001056e-03]] \n",
      "\n",
      "b2 =  [-4.47817315  0.97570809 -3.65027954  1.13073823  1.82183271  0.95644488] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NAND Gate 객체 생성 및 training\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([1, 1, 1, 0])\n",
    "\n",
    "nand_obj = LogicGate(\"NAND\", xdata, tdata)\n",
    "\n",
    "nand_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.99895072]), 1)\n",
      "(array([0.98388541]), 1)\n",
      "(array([0.98419633]), 1)\n",
      "(array([0.02818861]), 0)\n"
     ]
    }
   ],
   "source": [
    "# NAND Gate prediction\n",
    "\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(nand_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR object is created\n",
      "Initial loss value =  4.719492911419669\n",
      "\n",
      "*****************************************************************************\n",
      "step =  0   , loss value =  4.62576643873056\n",
      "\n",
      "W2 =  [[0.56513138 0.64985257 0.77769655 0.02929235 0.28361313 0.24628184]\n",
      " [0.22644505 0.36826693 0.4148508  0.47443348 0.08181696 0.79594833]] \n",
      "\n",
      "b2 =  [0.07151767 0.09746544 0.48548136 0.81132402 0.57809749 0.13768366] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  400   , loss value =  2.7765722603826277\n",
      "\n",
      "W2 =  [[0.55158193 0.64076033 0.76541389 0.02686919 0.27573738 0.22431077]\n",
      " [0.21760585 0.35621584 0.39238373 0.45527926 0.07218529 0.78916566]] \n",
      "\n",
      "b2 =  [0.0341333  0.08661174 0.48328521 0.76451813 0.56405573 0.13951978] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  800   , loss value =  2.775368482063537\n",
      "\n",
      "W2 =  [[0.55664347 0.63538205 0.75489275 0.04355977 0.27438153 0.19887838]\n",
      " [0.22734953 0.34764739 0.3720085  0.45718246 0.06790431 0.78022682]] \n",
      "\n",
      "b2 =  [0.03657573 0.08403324 0.48193625 0.7633951  0.56444186 0.13566407] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1200   , loss value =  2.7744144275097877\n",
      "\n",
      "W2 =  [[0.56176219 0.63124349 0.74749858 0.05901317 0.2730782  0.1757762 ]\n",
      " [0.23734398 0.34086484 0.35705298 0.4593965  0.06311425 0.77276715]] \n",
      "\n",
      "b2 =  [0.03931111 0.08192078 0.48081264 0.76256331 0.56482251 0.13230804] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  1600   , loss value =  2.77362814742775\n",
      "\n",
      "W2 =  [[0.5670032  0.62814871 0.74267997 0.0734733  0.27189458 0.15450678]\n",
      " [0.24768282 0.3356527  0.34694039 0.4618753  0.05786384 0.76650237]] \n",
      "\n",
      "b2 =  [0.0423446  0.08024978 0.47997847 0.7619543  0.56519808 0.12939867] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2000   , loss value =  2.7729511396606696\n",
      "\n",
      "W2 =  [[0.57242709 0.62594146 0.74005669 0.08713885 0.27089339 0.13467577]\n",
      " [0.25845476 0.33183666 0.34127117 0.46458868 0.05218651 0.7612267 ]] \n",
      "\n",
      "b2 =  [0.04568882 0.07899557 0.47947532 0.76151927 0.56557271 0.12689398] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2400   , loss value =  2.7723393858269962\n",
      "\n",
      "W2 =  [[0.57809298 0.62449538 0.73938476 0.10017359 0.27013642 0.115967  ]\n",
      " [0.2697469  0.32927321 0.3397909  0.46751837 0.04610389 0.75679375]] \n",
      "\n",
      "b2 =  [0.04936247 0.0781345  0.47933679 0.7612231  0.56595309 0.12476402] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  2800   , loss value =  2.7717574743675324\n",
      "\n",
      "W2 =  [[0.58406091 0.62370653 0.74053445 0.11271335 0.26968756 0.0981247 ]\n",
      " [0.28164727 0.32784138 0.3423697  0.47065481 0.03962825 0.75310345]] \n",
      "\n",
      "b2 =  [0.05338963 0.07764418 0.47959675 0.76104046 0.5663479  0.12299115] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3200   , loss value =  2.7711744393792235\n",
      "\n",
      "W2 =  [[0.59039383 0.62348764 0.74347824 0.12487055 0.26961548 0.0809405 ]\n",
      " [0.29424685 0.32743603 0.34899089 0.47399451 0.03276418 0.75009353]] \n",
      "\n",
      "b2 =  [0.0577993  0.07750317 0.48029429 0.76095299 0.56676767 0.12157   ] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  3600   , loss value =  2.7705604539809303\n",
      "\n",
      "W2 =  [[0.59715932 0.62376333 0.74828713 0.13673708 0.26999633 0.06424406]\n",
      " [0.3076412  0.32796195 0.35974721 0.47753768 0.02550973 0.74773396]] \n",
      "\n",
      "b2 =  [0.06262524 0.0776903  0.48147631 0.76094746 0.56722487 0.12050758] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4000   , loss value =  2.769883761663116\n",
      "\n",
      "W2 =  [[0.60443121 0.62446607 0.75513483 0.14838579 0.27091665 0.04789588]\n",
      " [0.32193175 0.32932847 0.37484388 0.4812859  0.01785724 0.74602394]] \n",
      "\n",
      "b2 =  [0.06790589 0.07818368 0.48319855 0.76101436 0.56773424 0.11982364] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4400   , loss value =  2.76910730557522\n",
      "\n",
      "W2 =  [[0.61229097 0.62553256 0.76430989 0.15987089 0.2724768  0.03178196]\n",
      " [0.33722661 0.33144417 0.39460844 0.48523983 0.00979392 0.74499095]] \n",
      "\n",
      "b2 =  [0.07368422 0.07895933 0.48552474 0.76114686 0.5683134  0.11955128] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  4800   , loss value =  2.768184459902893\n",
      "\n",
      "W2 =  [[0.62082895 0.62690016 0.77623666 0.17122718 0.27479507 0.01580951]\n",
      " [0.3536409  0.33421125 0.41950766 0.48939642 0.00130236 0.74469162]] \n",
      "\n",
      "b2 =  [0.08000756 0.07998952 0.48852277 0.76134006 0.56898368 0.11973813] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5200   , loss value =  2.7670530765597445\n",
      "\n",
      "W2 =  [[ 6.30145193e-01  6.28503478e-01  7.91506472e-01  1.82468254e-01\n",
      "   2.78012945e-01 -9.65995527e-05]\n",
      " [ 3.71296137e-01  3.37519491e-01  4.50172137e-01  4.93745914e-01\n",
      "  -7.63909792e-03  7.45214767e-01]] \n",
      "\n",
      "b2 =  [0.08692699 0.08124065 0.49225608 0.76159027 0.56977124 0.12044797] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  5600   , loss value =  2.7656267033159967\n",
      "\n",
      "W2 =  [[ 0.64034955  0.63027069  0.81092078  0.19358348  0.28230188 -0.01599693]\n",
      " [ 0.39031837  0.34123936  0.48742919  0.49826804 -0.01705591  0.74668672]] \n",
      "\n",
      "b2 =  [0.09449639 0.08267052 0.49676611 0.76189448 0.57070872 0.12176307] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6000   , loss value =  2.763781258852634\n",
      "\n",
      "W2 =  [[ 0.65156044  0.63211993  0.83554749  0.20453367  0.28787237 -0.03194043]\n",
      " [ 0.41083418  0.3452143   0.53234394  0.50292758 -0.02697682  0.74927977]] \n",
      "\n",
      "b2 =  [0.10277059 0.08422506 0.50203887 0.76224973 0.5718373  0.12378747] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6400   , loss value =  2.761334634650641\n",
      "\n",
      "W2 =  [[ 0.66390145  0.63395586  0.86678966  0.21524549  0.29498609 -0.04796748]\n",
      " [ 0.43296363  0.34925227  0.58626614  0.50766917 -0.03743331  0.75322473]] \n",
      "\n",
      "b2 =  [0.11180249 0.08583422 0.50794378 0.7626525  0.57320955 0.12665132] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  6800   , loss value =  2.7580157000951413\n",
      "\n",
      "W2 =  [[ 0.67749435  0.63566726  0.90646086  0.22560453  0.30397251 -0.06411333]\n",
      " [ 0.45680873  0.35311725  0.65087623  0.51241152 -0.04845906  0.75882885]] \n",
      "\n",
      "b2 =  [0.1216387  0.08740712 0.51412556 0.763098   0.57489283 0.13051652] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  7200   , loss value =  2.7534183316760807\n",
      "\n",
      "W2 =  [[ 0.69244675  0.63712714  0.95685196  0.23544793  0.31525155 -0.08041229]\n",
      " [ 0.48243571  0.35652214  0.72821614  0.51704194 -0.06008981  0.76650129]] \n",
      "\n",
      "b2 =  [0.13231367 0.08882662 0.51982135 0.76357934 0.57697312 0.13558354] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  7600   , loss value =  2.746936037103021\n",
      "\n",
      "W2 =  [[ 0.70883193  0.63819844  1.02075966  0.24455798  0.32936469 -0.09690317]\n",
      " [ 0.50984937  0.35912629  0.82068149  0.52141252 -0.07236417  0.77678831]] \n",
      "\n",
      "b2 =  [0.14384249 0.08994377 0.52357141 0.76408657 0.5795581  0.14209821] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8000   , loss value =  2.7376740599375387\n",
      "\n",
      "W2 =  [[ 0.72665852  0.63875032  1.10143526  0.25265994  0.34701772 -0.11363629]\n",
      " [ 0.53895795  0.36054301  0.93094693  0.52534104 -0.08532601  0.79042182]] \n",
      "\n",
      "b2 =  [0.15621405 0.09057261 0.52280751 0.76460552 0.58277642 0.15035555] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8400   , loss value =  2.7243372711158305\n",
      "\n",
      "W2 =  [[ 0.74582735  0.63869299  1.20242018  0.25942958  0.36914035 -0.13068124]\n",
      " [ 0.56952718  0.36036527  1.06181393  0.5286208  -0.0990279   0.80838646]] \n",
      "\n",
      "b2 =  [0.16938745 0.09048567 0.51336994 0.76511568 0.58676725 0.16069296] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  8800   , loss value =  2.705090058583295\n",
      "\n",
      "W2 =  [[ 0.766074    0.63804326  1.32728786  0.2645188   0.39697117 -0.14813134]\n",
      " [ 0.60112228  0.35822149  1.21602108  0.53104608 -0.11353098  0.83201526]] \n",
      "\n",
      "b2 =  [0.18329591 0.08940758 0.48915205 0.76558478 0.59164794 0.17345799] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************************************************************\n",
      "step =  9200   , loss value =  2.6773862184150374\n",
      "\n",
      "W2 =  [[ 0.78689778  0.63703845  1.47938948  0.26761112  0.4321799  -0.16609545]\n",
      " [ 0.63303694  0.35387792  1.39611205  0.53246205 -0.12889063  0.8631299 ]] \n",
      "\n",
      "b2 =  [0.19786014 0.08699769 0.44229921 0.76595379 0.59743959 0.18892282] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  9600   , loss value =  2.6378318045692386\n",
      "\n",
      "W2 =  [[ 0.80748774  0.63632268  1.66168213  0.26852304  0.47703118 -0.1846697 ]\n",
      " [ 0.66421591  0.34740977  1.60439531  0.53285211 -0.1451187   0.90423666]] \n",
      "\n",
      "b2 =  [0.2130017  0.08280055 0.36461658 0.76609924 0.603917   0.20709918] \n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "step =  10000   , loss value =  2.5823894030397563\n",
      "\n",
      "W2 =  [[ 0.82668577  0.63722285  1.87642975  0.26736595  0.5345429  -0.20391735]\n",
      " [ 0.69320874  0.3394574   1.84271888  0.53247445 -0.16215391  0.95873475]] \n",
      "\n",
      "b2 =  [0.22861637 0.07612926 0.25083001 0.76575535 0.61033975 0.22739283] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XOR Gate 객체 생성\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([0, 1, 1, 0])\n",
    "\n",
    "\n",
    "xor_obj = LogicGate(\"XOR\", xdata, tdata)\n",
    "\n",
    "xor_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.40671468]), 0)\n",
      "(array([0.51879867]), 1)\n",
      "(array([0.54015848]), 1)\n",
      "(array([0.54532765]), 1)\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(xor_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:su] *",
   "language": "python",
   "name": "conda-env-su-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
